[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thomas website",
    "section": "",
    "text": "Welcome to my website!\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Thomas’s resume",
    "section": "",
    "text": "Download PDF file.\nAbout this site"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Homework2 - Poisson Regression Examples\n\n\n\n\n\n\nThomas Chiang\n\n\nMay 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHomework1 - A Replication of Karlan and List (2007)\n\n\n\n\n\n\nThomas Chiang\n\n\nMay 1, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "My main project",
    "section": "",
    "text": "I like….\n\n\nI also…."
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "My main project",
    "section": "",
    "text": "I also…."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndf = pd.read_stata('/home/jovyan/code/MGTA 495/QUARTO_WEBSITE/data/karlan_list_2007.dta')\n\ndata_description = df.describe().loc[['mean', 'std']]\n\nprint(data_description)\n\nprint(df.info())\n\n      treatment   control    ratio2    ratio3    size25    size50   size100  \\\nmean   0.666813  0.333187  0.222311  0.222211  0.166723  0.166623  0.166723   \nstd    0.471357  0.471357  0.415803  0.415736  0.372732  0.372643  0.372732   \n\n        sizeno     askd1     askd2  ...    redcty   bluecty    pwhite  \\\nmean  0.166743  0.222311  0.222291  ...  0.510245  0.488715  0.819599   \nstd   0.372750  0.415803  0.415790  ...  0.499900  0.499878  0.168560   \n\n        pblack  page18_39  ave_hh_sz  median_hhincome    powner  psch_atlstba  \\\nmean  0.086710   0.321694   2.429012     54815.700533  0.669418      0.391661   \nstd   0.135868   0.103039   0.378105     22027.316665  0.193405      0.186599   \n\n      pop_propurban  \nmean       0.871968  \nstd        0.258633  \n\n[2 rows x 48 columns]\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n\n\n\nThere are 50,083 observations in the dataset.\nThe treatment column indicates whether the observation was part of the treatment group (1) or the control group (0), with a majority being in the treatment group.\nThe ratio column categorizes the match ratio, with ‘Control’ being the most frequent category, followed by ‘2’, ‘1’, and ‘3’, indicating different matching ratios for donations.\nThe size column indicates the match threshold, where ‘Control’ is the most common, implying many observations did not have a stated match threshold, followed by different threshold levels like $25,000, $100,000, and $50,000.\nThe ask column suggests donation amounts with ‘Control’ indicating no suggestion, and the rest being multiples of the highest previous contribution.\nThe amount column represents the dollars given, with an average donation of around $0.92, a maximum donation of $400, and a standard deviation indicating variability in donation amounts.\nThe gave column is a binary indicator of whether any donation was given, with a low overall mean, indicating a low response rate.\nDemographic variables such as pwhite, pblack, page18_39, ave_hh_sz, median_hhincome, powner, psch_atlstba, and pop_propurban give us information about the racial composition, age distribution, household size, income levels, homeownership, educational attainment, and urban population proportion within the zip codes of the donors.\nPolitical orientation is captured with variables like perbush (state vote share for Bush), red0 (red state), and blue0 (blue state), allowing for an analysis of donations based on political leanings.\nFor the categorical variables, we have the counts for each category in the treatment, ratio, size, and ask columns, giving us a sense of how the treatments were distributed across the sample.\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nfrom scipy import stats\nimport statsmodels.api as sm\n\n# Defining the treatment and control groups for the variable 'mrm2' (months since last donation)\ntreatment_mrm2 = df[df['treatment'] == 1]['mrm2']\ncontrol_mrm2 = df[df['treatment'] == 0]['mrm2']\n\n# Performing a t-test between treatment and control groups\nt_test_result = stats.ttest_ind(treatment_mrm2, control_mrm2, equal_var=False, nan_policy='omit')\n\n# Performing a linear regression of mrm2 on treatment\n# Adding a constant to the model for the intercept\nX = sm.add_constant(df['treatment'])\ny = df['mrm2']\nlinear_regression_result = sm.OLS(y, X, missing='drop').fit()\n\n# Extracting the coefficient for the treatment variable from the regression results\ntreatment_coefficient = linear_regression_result.params['treatment']\n\n# The p-value for the treatment coefficient in the regression should match the p-value from the t-test\nregression_p_value = linear_regression_result.pvalues['treatment']\n\nprint(t_test_result)\n\nprint('treatment_coefficient=',treatment_coefficient) \nprint('regression_p_value=',regression_p_value)\n\nTtestResult(statistic=0.11953155228177251, pvalue=0.9048549631450832, df=33394.47581389535)\ntreatment_coefficient= 0.013685851546783642\nregression_p_value= 0.9048859731777756\n\n\n\nT-Test: The t-test shows that the difference in the average months since the last donation between the treatment and control groups is not statistically significant at the 95% confidence level. The test statistic is approximately 0.12, and the p-value is 0.905, indicating that we fail to reject the null hypothesis that there is no difference in means between the two groups.\nLinear Regression: When we perform a linear regression of ‘mrm2’ on the treatment variable, the estimated coefficient for the treatment variable is approximately 0.014. The p-value for this coefficient is 0.905, which matches the p-value from the t-test, confirming that there is no statistically significant difference at the 95% confidence level.\n\nBoth methods, the t-test and the linear regression, yield the same conclusion, demonstrating the balance between the treatment and control groups regarding the months since the last donation. This is consistent with what we would expect if the randomization process was successful. The lack of significant differences in pre-treatment characteristics like ‘mrm2’ supports the validity of the experiment’s design, as shown in Table 1 of the paper, which likely serves to demonstrate that randomization created equivalent groups and that the treatment effect can be attributed to the treatment itself rather than pre-existing differences."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n# Calculating the proportion of people who donated in both treatment and control groups\nproportion_treatment_donated = df[df['treatment'] == 1]['gave'].mean()\nproportion_control_donated = df[df['treatment'] == 0]['gave'].mean()\n\n# Data to plot\nproportions = [proportion_control_donated, proportion_treatment_donated]\ngroup_labels = ['Control', 'Treatment']\n\n# Creating the bar plot\nplt.figure(figsize=(10, 6))\n\nlabels = ['Treatment', 'Control']\nbars = plt.bar(labels, proportions, color=['orange', 'blue'])\n\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.2%}', ha='center', va='bottom')\nplt.ylabel('Proportion Who Donated')\nplt.title('Proportion of People Who Made a Charitable Contribution')\nplt.ylim(0, max(proportions) + 0.05)  # Set y-axis limit to add some space above the highest bar\nplt.show()\n\n\n\n\n\n\n\n\nEach bar is the proportion of people who donated. One bar for treatment and one bar for control.\nAs observed, the bar for the treatment group is slightly higher than that for the control group, suggesting a higher donation response rate in the treatment group.\n\n# Performing a t-test on the binary outcome of whether any charitable donation was made ('gave' column)\ntreatment_gave = df[df['treatment'] == 1]['gave']\ncontrol_gave = df[df['treatment'] == 0]['gave']\n\n# T-test\nt_test_gave = stats.ttest_ind(treatment_gave, control_gave, equal_var=False)\n\n# Bivariate Linear Regression for the same binary outcome\nX_gave = sm.add_constant(df['treatment'])\ny_gave = df['gave']\nlinear_regression_gave = sm.OLS(y_gave, X_gave, missing='drop').fit()\n\n# Results from the linear regression\nregression_results_gave = linear_regression_gave.summary()\n\nt_test_gave, regression_results_gave.tables[1]\n\nprint(regression_results_gave)\n\nprint(t_test_gave)\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):            0.00193\nTime:                        05:20:41   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nTtestResult(statistic=3.2094621908279835, pvalue=0.001330982345091417, df=36576.84238986656)\n\n\nThe t-test between the treatment and control groups for the binary outcome of whether any charitable donation was made shows a statistically significant difference. The test statistic is approximately 3.21 and the p-value is 0.0013, which is below the 0.05 threshold typically used for statistical significance. This implies that the treatment had a significant effect on the likelihood of making a donation compared to the control group.\nThe bivariate linear regression that regresses the binary outcome of giving on the treatment indicator also demonstrates this finding. The coefficient associated with the treatment variable in the regression will indicate the average effect of the treatment on the probability of giving.\nIn the context of the experiment, the significant p-value and the positive test statistic suggest that the matched donations (treatment) lead to an increased likelihood of making a donation. Interpreting these results in terms of human behavior, we can infer that individuals are more likely to contribute to a charitable cause when their donation is being matched by another party. This could be due to a perceived increase in the value of their donation, or it may trigger a sense of social participation or responsibility.\nThe statistical results align with Table 2a Panel A from the paper, confirming the robustness of the experiment’s findings and providing evidence that matched donations can indeed influence donation behavior.\n\n# Running a probit regression where the outcome variable is 'gave' and the explanatory variable is 'treatment'\nprobit_model = sm.Probit(y_gave, X_gave).fit()\n\n# Displaying the results of the probit regression\nprobit_results = probit_model.summary()\n\n# Specifically, we're interested in the coefficient of 'treatment' variable and its p-value to compare with Table 3, column 1\nprobit_coefficient = probit_model.params['treatment']\nprobit_p_value = probit_model.pvalues['treatment']\n\nprint(probit_results.tables[1])\nprint('probit_coefficient=',probit_coefficient)\nprint('probit_p_value=',probit_p_value)\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\nprobit_coefficient= 0.08678462244745852\nprobit_p_value= 0.001852399014778513\n\n\nProbit regression\nThe coefficient and the level of significance for the treatment effect in our regression match exactly with the results presented in the paper. This suggests that our model has successfully replicated the finding in Table 3, column 1 of the paper, confirming that the treatment (receiving a matching offer) has a positive and significant effect on the likelihood of making a donation.\nFor a thorough replication, including the control column is not necessary because the treatment variable captures the effect of being in the treatment group compared to the control group. The control group is inherently part of the baseline against which the treatment effect is measured. Therefore, the model is correctly specified by including only the treatment variable to match the results presented in Table 3, column 1 of the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\ndf['ratio_1'] = (df['ratio'] == 1).astype(int)\ndf['ratio_2'] = (df['ratio2'] == 1).astype(int)\ndf['ratio_3'] = (df['ratio3'] == 1).astype(int)\n\nratio_1 = df[df['ratio_1'] == 1]\nratio_2 = df[df['ratio_2'] == 1]\nratio_3 = df[df['ratio_3'] == 1]\n# 1:1 vs 2:1\nt_test_1_vs_2 = stats.ttest_ind(ratio_1['gave'], ratio_2['gave']\n, equal_var=False)\n\n# 1:1 vs 3:1\nt_test_1_vs_3 = stats.ttest_ind(ratio_1['gave'], ratio_3['gave'], equal_var=False)\n\n# 2:1 vs 3:1\nt_test_2_vs_3 = stats.ttest_ind(ratio_2['gave'], ratio_3['gave'], equal_var=False)\n\nt_test_1_vs_2, t_test_1_vs_3, t_test_2_vs_3\n\n(TtestResult(statistic=-0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836),\n TtestResult(statistic=-1.0150174470156275, pvalue=0.31010856527625774, df=22215.0529778684),\n TtestResult(statistic=-0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778))\n\n\n\n1:1 vs 2:1 and 1:1 vs 3:1: The p-values are greater than the common significance level (0.05), indicating no significant difference in the likelihood of donating between the 1:1 match ratio and either the 2:1 or 3:1 match ratios.\n2:1 vs 3:1: Similarly, the p-value is much greater than 0.05, showing no statistically significant difference between these two higher match ratios.\n\nThese results suggest that increasing the match ratio from 1:1 to 2:1 or 3:1 does not significantly increase the probability that someone donates, aligning with the authors’ observations that larger match ratios do not have additional impact over a 1:1 match in motivating donations.\n\n# Logistic regression: regressing 'gave' on 'ratio2' and 'ratio3'\nX = df[['ratio_1','ratio_2', 'ratio_3']]  # Independent variables\nX = sm.add_constant(X)  # Adding a constant for the intercept\ny = df['gave']  # Dependent variable\n\n# Fit the logistic regression model\nmodel = sm.Logit(y, X).fit()\n\n# Summary of the model\nmodel.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100430\n         Iterations 8\n\n\n\nLogit Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nLogit\nDf Residuals:\n50079\n\n\nMethod:\nMLE\nDf Model:\n3\n\n\nDate:\nTue, 16 Apr 2024\nPseudo R-squ.:\n0.001108\n\n\nTime:\n05:20:42\nLog-Likelihood:\n-5029.8\n\n\nconverged:\nTrue\nLL-Null:\n-5035.4\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.01091\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-4.0073\n0.058\n-68.556\n0.000\n-4.122\n-3.893\n\n\nratio_1\n0.1530\n0.089\n1.728\n0.084\n-0.021\n0.327\n\n\nratio_2\n0.2418\n0.086\n2.797\n0.005\n0.072\n0.411\n\n\nratio_3\n0.2463\n0.086\n2.852\n0.004\n0.077\n0.416\n\n\n\n\n\nModel Coefficients:\nIntercept: The baseline log odds of giving when none of the specific match ratios are applied is -4.0073.\n\nratio_1 Coefficient: The change in log odds of giving for a 1:1 match ratio over the baseline (constant) is 0.1530. This effect is not statistically significant (p-value = 0.084), suggesting that the 1:1 match ratio does not significantly differ from the baseline when controlling for other ratios.\nratio_2 Coefficient: The log odds of giving for a 2:1 match ratio is higher by 0.2418 compared to the baseline (no match). This is statistically significant (p-value = 0.005).\nratio_3 Coefficient: The log odds of giving for a 3:1 match ratio increase by 0.2463 compared to the baseline, also statistically significant (p-value = 0.004).\n\nInterpretation:\nThe coefficients for both ratio_2 and ratio_3 indicate a positive and statistically significant effect on the likelihood of making a donation compared to when no specific match ratio is applied (baseline). This aligns with the notion that higher match ratios (2:1 and 3:1) increase the likelihood of donating more than no specific match condition or possibly the control condition.\nThe model’s pseudo R-squared is still very low, indicating that although the match ratio is statistically significant, its overall explanatory power on the likelihood of donating is quite limited.\nThis model effectively addresses the question by assessing the impact of different match ratios using regression analysis and clarifies how each ratio compares to a baseline scenario where no specific match condition is mentioned.\nThe code below calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios.\n\nimport numpy as np\n\n# Direct Calculation from Data\nresponse_rate_1 = df[df['ratio_1'] == 1]['gave'].mean()\nresponse_rate_2 = df[df['ratio_2'] == 1]['gave'].mean()\nresponse_rate_3 = df[df['ratio_3'] == 1]['gave'].mean()\n\ndiff_1_to_2_data = response_rate_2 - response_rate_1\ndiff_2_to_3_data = response_rate_3 - response_rate_2\n\n# Convert differences in log odds to differences in probability\ncoef_ratio_1 = 0.1530\ncoef_ratio_2 = 0.2418\ncoef_ratio_3 = 0.2463\n\n# Convert log-odds to odds\nodds_ratio_1 = np.exp(coef_ratio_1)\nodds_ratio_2 = np.exp(coef_ratio_2)\nodds_ratio_3 = np.exp(coef_ratio_3)\n\n# Convert odds to probabilities\nprob_ratio_1 = odds_ratio_1 / (1 + odds_ratio_1)\nprob_ratio_2 = odds_ratio_2 / (1 + odds_ratio_2)\nprob_ratio_3 = odds_ratio_3 / (1 + odds_ratio_3)\n\n# Compute differences in probabilities\ndiff_prob_1_to_2 = prob_ratio_2 - prob_ratio_1\ndiff_prob_2_to_3 = prob_ratio_3 - prob_ratio_2\n\n\nprint('Response Rate for 1:1 Match =',response_rate_1) \nprint('Response Rate for 2:1 Match =',response_rate_2)\nprint('Response Rate for 3:1 Match =',response_rate_3)\nprint('Difference in Response Rate from 1:1 to 2:1 =',diff_1_to_2_data)\nprint('Difference in Response Rate from 2:1 to 3:1 =',diff_2_to_3_data)\nprint('Difference in Probability from 1:1 to 2:1 =',diff_prob_1_to_2)\nprint('Difference in Probability from 2:1 to 3:1 =',diff_prob_2_to_3)\n\nResponse Rate for 1:1 Match = 0.020749124225276205\nResponse Rate for 2:1 Match = 0.0226333752469912\nResponse Rate for 3:1 Match = 0.022733399227244138\nDifference in Response Rate from 1:1 to 2:1 = 0.0018842510217149944\nDifference in Response Rate from 2:1 to 3:1 = 0.00010002398025293902\nDifference in Probability from 1:1 to 2:1 = 0.02198162510978996\nDifference in Probability from 2:1 to 3:1 = 0.0011084130839175144\n\n\nDirect Data Analysis:\n\nThere is a small increase in response rate when moving from a 1:1 to a 2:1 match ratio (0.19%), indicating a slight effectiveness in increasing donations.\nThe increase from a 2:1 to a 3:1 match ratio is very minimal (0.01%), suggesting diminishing returns or nearly no additional benefit from increasing the match ratio beyond 2:1.\n\nRegression Analysis:\n\nThe regression model shows a significant relative increase (2.20%) in the probability of donating when moving from a 1:1 to a 2:1 match ratio, indicating a notable impact on donation likelihood.\nThe increase from 2:1 to 3:1 in probability (0.11%) is small, aligning with the direct data analysis that suggests minimal additional benefit from moving to even higher match ratios.\n\nThese findings suggest that while increasing the match ratio from 1:1 to 2:1 does increase the likelihood of donations, the incremental benefit of further increasing the ratio to 3:1 is very limited. This could help organizations optimize their matching strategies, potentially favoring a 2:1 ratio over higher ratios which do not appear to significantly boost donation rates beyond that point.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nThe code below is to calculate a t-test and run a bivariate linear regression of the donation amount on the treatment status.\n\n# Define the control group (where 'control' column is 1)\ncontrol_group_amount = df[df['control'] == 1]['amount']\n\n# Define the treatment group (where 'treatment' column is 1)\ntreatment_group_amount = df[df['treatment'] == 1]['amount']\n\n# Perform t-test between control and treatment groups\nt_test_result = stats.ttest_ind(control_group_amount, treatment_group_amount, equal_var=False)\n\n# Run a bivariate linear regression of donation amount on treatment status\nX_treat = sm.add_constant(df['treatment'])  # Treatment status with constant\ny_amount = df['amount']  # Donation amount\n\n# Fit the linear regression model\nlinear_model = sm.OLS(y_amount, X_treat).fit()\n\n# Display results from t-test and linear regression\nlinear_model.summary(), t_test_result\n\n(&lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                 amount   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     3.461\n Date:                Tue, 16 Apr 2024   Prob (F-statistic):             0.0628\n Time:                        05:20:42   Log-Likelihood:            -1.7946e+05\n No. Observations:               50083   AIC:                         3.589e+05\n Df Residuals:                   50081   BIC:                         3.589e+05\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const          0.8133      0.067     12.063      0.000       0.681       0.945\n treatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n ==============================================================================\n Omnibus:                    96861.113   Durbin-Watson:                   2.008\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\n Skew:                          15.297   Prob(JB):                         0.00\n Kurtosis:                     341.269   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\",\n TtestResult(statistic=-1.9182618934467577, pvalue=0.055085665289183336, df=36216.05660774625))\n\n\n\nThe results suggest that there is a potential increase in the amount donated when individuals are in the treatment group (receiving some form of matched donation offer) compared to the control group (not receiving a matched donation offer), but this increase is not definitively proven with these tests.\nThe statistical significance is marginal, and the effect size is small, meaning that while the treatment might influence the amount given, the effect is not large.\nThis analysis is beneficial as it provides an initial understanding of the relationship between match offers and donation behavior. Further analysis might involve looking at the specific sizes of match ratios to identify which are most effective.\n\nWhat if we limit the data to just people who made a donation and repeat the previous analysis?\n\n# To limit the data to just people who made a donation, we filter the DataFrame\ndf_donors = df[df['amount'] &gt; 0]\n\n# Perform the t-test between control and treatment groups for donors only\ncontrol_group_donors = df_donors[df_donors['control'] == 1]['amount']\ntreatment_group_donors = df_donors[df_donors['treatment'] == 1]['amount']\nt_test_donors_result = stats.ttest_ind(control_group_donors, treatment_group_donors, equal_var=False)\n\n# Run a bivariate linear regression of donation amount on treatment status for donors only\nX_donors = sm.add_constant(df_donors['treatment'])  # Treatment status with constant\ny_donors_amount = df_donors['amount']  # Donation amount\n\n# Fit the linear regression model for donors\nlinear_model_donors = sm.OLS(y_donors_amount, X_donors).fit()\n\n# Display results from t-test and linear regression for donors\nlinear_model_donors.summary(),t_test_donors_result\n\n(&lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                 amount   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                 -0.001\n Method:                 Least Squares   F-statistic:                    0.3374\n Date:                Tue, 16 Apr 2024   Prob (F-statistic):              0.561\n Time:                        05:20:42   Log-Likelihood:                -5326.8\n No. Observations:                1034   AIC:                         1.066e+04\n Df Residuals:                    1032   BIC:                         1.067e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const         45.5403      2.423     18.792      0.000      40.785      50.296\n treatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n ==============================================================================\n Omnibus:                      587.258   Durbin-Watson:                   2.031\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\n Skew:                           2.464   Prob(JB):                         0.00\n Kurtosis:                      13.307   Cond. No.                         3.49\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\",\n TtestResult(statistic=0.5846089794983359, pvalue=0.5590471865673547, df=557.4599304243758))\n\n\nThe negative coefficient for the treatment could suggest that the treatment (receiving some form of matched donation offer) does not necessarily lead to larger donations among those who chose to donate.\n\nimport matplotlib.pyplot as plt\n\n# Histogram for the treatment group\nplt.figure(figsize=(14, 6))\n\n# Treatment histogram\nplt.subplot(1, 2, 1)\nplt.hist(treatment_group_donors, bins=30, color='blue', alpha=0.7)\nplt.axvline(treatment_group_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group Donation Amounts')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(axis='y', alpha=0.75)\nplt.text(treatment_group_donors.mean() * 1.1, plt.ylim()[1] * 0.9, f'Average: ${treatment_group_donors.mean():.2f}',\n         color='red')\n\n# Control histogram\nplt.subplot(1, 2, 2)\nplt.hist(control_group_donors, bins=30, color='green', alpha=0.7)\nplt.axvline(control_group_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group Donation Amounts')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(axis='y', alpha=0.75)\nplt.text(control_group_donors.mean() * 1.1, plt.ylim()[1] * 0.9, f'Average: ${control_group_donors.mean():.2f}',\n         color='red')\n\n# Show the plots\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe histogram on the left represents the treatment group, with a sample average donation amount indicated by a red dashed line.\nThe histogram on the right shows the control group, also with the sample average marked by a red dashed line.\n\nIn both histograms, most of the donations are clustered at the lower end of the scale, with fewer large donations. This is a common pattern in charitable giving, where many small donations are accompanied by a smaller number of larger gifts."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n# Importing the necessary libraries for simulation\nfrom scipy.stats import bernoulli\n\n# Setting the probabilities for control and treatment groups\np_control = 0.018\np_treatment = 0.022\n\n# Simulating 100,000 draws from the control distribution\ncontrol_sim = bernoulli.rvs(p_control, size=100000)\n\n# Simulating 10,000 draws from the treatment distribution\ntreatment_sim = bernoulli.rvs(p_treatment, size=10000)\n\n# Calculate the vector of 10,000 differences\n# For each of the first 10,000 elements in the control group,\n# we calculate the difference to the corresponding (by index) element in the treatment group.\n# We then calculate the cumulative average of these differences.\ndifferences = treatment_sim[:10000] - control_sim[:10000]\ncumulative_average = np.cumsum(differences) / np.arange(1, 10001)\n\n# Plotting the cumulative average of differences\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_average, color='red')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average of Difference')\nplt.title('Cumulative Average Difference Between Treatment and Control')\nplt.axhline((p_treatment - p_control), color='blue', linestyle='dashed', linewidth=1)\nplt.text(10000, (p_treatment - p_control), f'True Difference: {p_treatment - p_control:.4f}', color='blue', ha='right')\nplt.show()\n\n\n\n\n\n\n\n\nThe plot shows the cumulative average difference between the treatment and control groups over 10,000 simulations. As the number of simulations increases, the cumulative average difference begins to stabilize and approaches the true difference in probabilities (0.004, shown by the blue dashed line).\nInitially, there’s considerable volatility because the cumulative average can be greatly affected by a small number of draws. However, as we accumulate more samples, each additional sample has a smaller impact on the cumulative average, which starts to converge towards the true difference between the probabilities of making a donation in the treatment and control groups.\nThis illustrates the Law of Large Numbers in action: as the sample size grows, the sample average becomes a more accurate estimate of the population parameter. The plot confirms that the cumulative average approaches the true difference, validating that the simulation behaves as expected according to the law.\nFrom this, we learn that even with random fluctuations in data (as seen in the earlier part of the graph), given enough data points, our estimates will get closer to the true underlying parameters we’re trying to measure. This reinforces the value of large sample sizes in statistical analysis for achieving reliable estimates\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects/project1/hw1_questions.html",
    "href": "projects/project1/hw1_questions.html",
    "title": "Homework1 - A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nBy randomly assigning one of these three treatments to each of the 50,000 letters, Karlan and List could observe the differences in response rates and donation amounts that resulted from the different types of letters. This randomization is key to the experiment because it helps ensure that any differences in outcomes are due to the type of letter received and not some other factor.\nThe goal of the experiment was not just to see if people would give, but whether they would give more or less depending on the type of appeal made in the letter. It’s a study of how messaging and perceived incentives can affect charitable giving.\nThe goal of this project is to replicate their results, using the available data to see if we can achieve the same findings, thus reinforcing the conclusions drawn from the original study."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#introduction",
    "href": "projects/project1/hw1_questions.html#introduction",
    "title": "Homework1 - A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nBy randomly assigning one of these three treatments to each of the 50,000 letters, Karlan and List could observe the differences in response rates and donation amounts that resulted from the different types of letters. This randomization is key to the experiment because it helps ensure that any differences in outcomes are due to the type of letter received and not some other factor.\nThe goal of the experiment was not just to see if people would give, but whether they would give more or less depending on the type of appeal made in the letter. It’s a study of how messaging and perceived incentives can affect charitable giving.\nThe goal of this project is to replicate their results, using the available data to see if we can achieve the same findings, thus reinforcing the conclusions drawn from the original study."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#data",
    "href": "projects/project1/hw1_questions.html#data",
    "title": "Homework1 - A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndf = pd.read_stata('/home/jovyan/code/MGTA 495/QUARTO_WEBSITE/data/karlan_list_2007.dta')\n\ndata_description = df.describe().loc[['mean', 'std']]\n\nprint(data_description)\n\nprint(df.info())\n\n      treatment   control    ratio2    ratio3    size25    size50   size100  \\\nmean   0.666813  0.333187  0.222311  0.222211  0.166723  0.166623  0.166723   \nstd    0.471357  0.471357  0.415803  0.415736  0.372732  0.372643  0.372732   \n\n        sizeno     askd1     askd2  ...    redcty   bluecty    pwhite  \\\nmean  0.166743  0.222311  0.222291  ...  0.510245  0.488715  0.819599   \nstd   0.372750  0.415803  0.415790  ...  0.499900  0.499878  0.168560   \n\n        pblack  page18_39  ave_hh_sz  median_hhincome    powner  psch_atlstba  \\\nmean  0.086710   0.321694   2.429012     54815.700533  0.669418      0.391661   \nstd   0.135868   0.103039   0.378105     22027.316665  0.193405      0.186599   \n\n      pop_propurban  \nmean       0.871968  \nstd        0.258633  \n\n[2 rows x 48 columns]\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n\n\n\nThere are 50,083 observations in the dataset.\nThe treatment column indicates whether the observation was part of the treatment group (1) or the control group (0), with a majority being in the treatment group.\nThe ratio column categorizes the match ratio, with ‘Control’ being the most frequent category, followed by ‘2’, ‘1’, and ‘3’, indicating different matching ratios for donations.\nThe size column indicates the match threshold, where ‘Control’ is the most common, implying many observations did not have a stated match threshold, followed by different threshold levels like $25,000, $100,000, and $50,000.\nThe ask column suggests donation amounts with ‘Control’ indicating no suggestion, and the rest being multiples of the highest previous contribution.\nThe amount column represents the dollars given, with an average donation of around $0.92, a maximum donation of $400, and a standard deviation indicating variability in donation amounts.\nThe gave column is a binary indicator of whether any donation was given, with a low overall mean, indicating a low response rate.\nDemographic variables such as pwhite, pblack, page18_39, ave_hh_sz, median_hhincome, powner, psch_atlstba, and pop_propurban give us information about the racial composition, age distribution, household size, income levels, homeownership, educational attainment, and urban population proportion within the zip codes of the donors.\nPolitical orientation is captured with variables like perbush (state vote share for Bush), red0 (red state), and blue0 (blue state), allowing for an analysis of donations based on political leanings.\nFor the categorical variables, we have the counts for each category in the treatment, ratio, size, and ask columns, giving us a sense of how the treatments were distributed across the sample.\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nfrom scipy import stats\nimport statsmodels.api as sm\n\n# Defining the treatment and control groups for the variable 'mrm2' (months since last donation)\ntreatment_mrm2 = df[df['treatment'] == 1]['mrm2']\ncontrol_mrm2 = df[df['treatment'] == 0]['mrm2']\n\n# Performing a t-test between treatment and control groups\nt_test_result = stats.ttest_ind(treatment_mrm2, control_mrm2, equal_var=False, nan_policy='omit')\n\nX = sm.add_constant(df['treatment'])\ny = df['mrm2']\nlinear_regression_result = sm.OLS(y, X, missing='drop').fit()\n\n# Extracting the coefficient for the treatment variable from the regression results\ntreatment_coefficient = linear_regression_result.params['treatment']\n\n# The p-value for the treatment coefficient in the regression should match the p-value from the t-test\nregression_p_value = linear_regression_result.pvalues['treatment']\n\nprint(t_test_result)\n\nprint('treatment_coefficient=',treatment_coefficient) \nprint('regression_p_value=',regression_p_value)\n\nTtestResult(statistic=0.11953155228177251, pvalue=0.9048549631450832, df=33394.47581389535)\ntreatment_coefficient= 0.013685851546783642\nregression_p_value= 0.9048859731777756\n\n\n\nT-Test: The t-test shows that the difference in the average months since the last donation between the treatment and control groups is not statistically significant at the 95% confidence level. The test statistic is approximately 0.12, and the p-value is 0.905, indicating that we fail to reject the null hypothesis that there is no difference in means between the two groups.\nLinear Regression: When we perform a linear regression of ‘mrm2’ on the treatment variable, the estimated coefficient for the treatment variable is approximately 0.014. The p-value for this coefficient is 0.905, which matches the p-value from the t-test, confirming that there is no statistically significant difference at the 95% confidence level.\n\nBoth methods, the t-test and the linear regression, yield the same conclusion, demonstrating the balance between the treatment and control groups regarding the months since the last donation. This is consistent with what we would expect if the randomization process was successful. The lack of significant differences in pre-treatment characteristics like ‘mrm2’ supports the validity of the experiment’s design, as shown in Table 1 of the paper, which likely serves to demonstrate that randomization created equivalent groups and that the treatment effect can be attributed to the treatment itself rather than pre-existing differences."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#experimental-results",
    "href": "projects/project1/hw1_questions.html#experimental-results",
    "title": "Homework1 - A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n# Calculating the proportion of people who donated in both treatment and control groups\nproportion_treatment_donated = df[df['treatment'] == 1]['gave'].mean()\nproportion_control_donated = df[df['treatment'] == 0]['gave'].mean()\n\n# Data to plot\nproportions = [proportion_control_donated, proportion_treatment_donated]\ngroup_labels = ['Control', 'Treatment']\n\n# Creating the bar plot\nplt.figure(figsize=(10, 6))\n\nlabels = ['Treatment', 'Control']\nbars = plt.bar(labels, proportions, color=['orange', 'blue'], edgecolor= ['black'])\n\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.2%}', ha='center', va='bottom')\nplt.ylabel('Proportion Who Donated')\nplt.title('Proportion of People Who Made a Charitable Contribution')\nplt.ylim(0, max(proportions) + 0.05)  # Set y-axis limit to add some space above the highest bar\nplt.show()\n\n\n\n\n\n\n\n\nEach bar is the proportion of people who donated. One bar for treatment and one bar for control.\nAs observed, the bar for the treatment group is slightly higher than that for the control group, suggesting a higher donation response rate in the treatment group.\n\n# Performing a t-test on the binary outcome of whether any charitable donation was made ('gave' column)\ntreatment_gave = df[df['treatment'] == 1]['gave']\ncontrol_gave = df[df['treatment'] == 0]['gave']\n\n# T-test\nt_test_gave = stats.ttest_ind(treatment_gave, control_gave, equal_var=False)\n\n# Bivariate Linear Regression for the same binary outcome\nX_gave = sm.add_constant(df['treatment'])\ny_gave = df['gave']\nlinear_regression_gave = sm.OLS(y_gave, X_gave, missing='drop').fit()\n\n# Results from the linear regression\nregression_results_gave = linear_regression_gave.summary()\n\nt_test_gave, regression_results_gave.tables[1]\n\nprint(regression_results_gave)\n\nprint(t_test_gave)\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):            0.00193\nTime:                        16:12:21   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nTtestResult(statistic=3.2094621908279835, pvalue=0.001330982345091417, df=36576.84238986656)\n\n\nThe t-test between the treatment and control groups for the binary outcome of whether any charitable donation was made shows a statistically significant difference. The test statistic is approximately 3.21 and the p-value is 0.0013, which is below the 0.05 threshold typically used for statistical significance. This implies that the treatment had a significant effect on the likelihood of making a donation compared to the control group.\nThe bivariate linear regression that regresses the binary outcome of giving on the treatment indicator also demonstrates this finding. The coefficient associated with the treatment variable in the regression will indicate the average effect of the treatment on the probability of giving.\nIn the context of the experiment, the significant p-value and the positive test statistic suggest that the matched donations (treatment) lead to an increased likelihood of making a donation. Interpreting these results in terms of human behavior, we can infer that individuals are more likely to contribute to a charitable cause when their donation is being matched by another party. This could be due to a perceived increase in the value of their donation, or it may trigger a sense of social participation or responsibility.\nThe statistical results align with Table 2a Panel A from the paper, confirming the robustness of the experiment’s findings and providing evidence that matched donations can indeed influence donation behavior.\n\n# Running a probit regression where the outcome variable is 'gave' and the explanatory variable is 'treatment'\nprobit_model = sm.Probit(y_gave, X_gave).fit()\n\nprobit_results = probit_model.summary()\n\nprobit_coefficient = probit_model.params['treatment']\nprobit_p_value = probit_model.pvalues['treatment']\n\nprint(probit_results.tables[1])\nprint('probit_coefficient=',probit_coefficient)\nprint('probit_p_value=',probit_p_value)\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\nprobit_coefficient= 0.08678462244745852\nprobit_p_value= 0.001852399014778513\n\n\nProbit regression\nThe coefficient and the level of significance for the treatment effect in our regression match exactly with the results presented in the paper. This suggests that our model has successfully replicated the finding in Table 3, column 1 of the paper, confirming that the treatment (receiving a matching offer) has a positive and significant effect on the likelihood of making a donation.\nFor a thorough replication, including the control column is not necessary because the treatment variable captures the effect of being in the treatment group compared to the control group. The control group is inherently part of the baseline against which the treatment effect is measured. Therefore, the model is correctly specified by including only the treatment variable to match the results presented in Table 3, column 1 of the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\ndf['ratio_1'] = (df['ratio'] == 1).astype(int)\ndf['ratio_2'] = (df['ratio2'] == 1).astype(int)\ndf['ratio_3'] = (df['ratio3'] == 1).astype(int)\n\nratio_1 = df[df['ratio_1'] == 1]\nratio_2 = df[df['ratio_2'] == 1]\nratio_3 = df[df['ratio_3'] == 1]\n\n# 1:1 vs 2:1\nt_test_1_vs_2 = stats.ttest_ind(ratio_1['gave'], ratio_2['gave']\n, equal_var=False)\n\n# 1:1 vs 3:1\nt_test_1_vs_3 = stats.ttest_ind(ratio_1['gave'], ratio_3['gave'], equal_var=False)\n\n# 2:1 vs 3:1\nt_test_2_vs_3 = stats.ttest_ind(ratio_2['gave'], ratio_3['gave'], equal_var=False)\n\nt_test_1_vs_2, t_test_1_vs_3, t_test_2_vs_3\n\n(TtestResult(statistic=-0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836),\n TtestResult(statistic=-1.0150174470156275, pvalue=0.31010856527625774, df=22215.0529778684),\n TtestResult(statistic=-0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778))\n\n\n\n1:1 vs 2:1 and 1:1 vs 3:1: The p-values are greater than the common significance level (0.05), indicating no significant difference in the likelihood of donating between the 1:1 match ratio and either the 2:1 or 3:1 match ratios.\n2:1 vs 3:1: Similarly, the p-value is much greater than 0.05, showing no statistically significant difference between these two higher match ratios.\n\nThese results suggest that increasing the match ratio from 1:1 to 2:1 or 3:1 does not significantly increase the probability that someone donates, aligning with the authors’ observations that larger match ratios do not have additional impact over a 1:1 match in motivating donations.\n\n# Logistic regression: regressing 'gave' on 'ratio2' and 'ratio3'\nX = df[['ratio_1','ratio_2', 'ratio_3']]  # Independent variables\nX = sm.add_constant(X)  # Adding a constant for the intercept\ny = df['gave']  # Dependent variable\n\n# Fit the logistic regression model\nmodel = sm.Logit(y, X).fit()\n\nmodel.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100430\n         Iterations 8\n\n\n\nLogit Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nLogit\nDf Residuals:\n50079\n\n\nMethod:\nMLE\nDf Model:\n3\n\n\nDate:\nTue, 16 Apr 2024\nPseudo R-squ.:\n0.001108\n\n\nTime:\n16:12:22\nLog-Likelihood:\n-5029.8\n\n\nconverged:\nTrue\nLL-Null:\n-5035.4\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.01091\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-4.0073\n0.058\n-68.556\n0.000\n-4.122\n-3.893\n\n\nratio_1\n0.1530\n0.089\n1.728\n0.084\n-0.021\n0.327\n\n\nratio_2\n0.2418\n0.086\n2.797\n0.005\n0.072\n0.411\n\n\nratio_3\n0.2463\n0.086\n2.852\n0.004\n0.077\n0.416\n\n\n\n\n\nModel Coefficients:\nIntercept: The baseline log odds of giving when none of the specific match ratios are applied is -4.0073.\n\nratio_1 Coefficient: The change in log odds of giving for a 1:1 match ratio over the baseline (constant) is 0.1530. This effect is not statistically significant (p-value = 0.084), suggesting that the 1:1 match ratio does not significantly differ from the baseline when controlling for other ratios.\nratio_2 Coefficient: The log odds of giving for a 2:1 match ratio is higher by 0.2418 compared to the baseline (no match). This is statistically significant (p-value = 0.005).\nratio_3 Coefficient: The log odds of giving for a 3:1 match ratio increase by 0.2463 compared to the baseline, also statistically significant (p-value = 0.004).\n\nInterpretation:\nThe coefficients for both ratio_2 and ratio_3 indicate a positive and statistically significant effect on the likelihood of making a donation compared to when no specific match ratio is applied (baseline). This aligns with the notion that higher match ratios (2:1 and 3:1) increase the likelihood of donating more than no specific match condition or possibly the control condition.\nThe model’s pseudo R-squared is still very low, indicating that although the match ratio is statistically significant, its overall explanatory power on the likelihood of donating is quite limited.\nThis model effectively addresses the question by assessing the impact of different match ratios using regression analysis and clarifies how each ratio compares to a baseline scenario where no specific match condition is mentioned.\nThe code below calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios.\n\nimport numpy as np\n\n# Direct Calculation from Data\nresponse_rate_1 = df[df['ratio_1'] == 1]['gave'].mean()\nresponse_rate_2 = df[df['ratio_2'] == 1]['gave'].mean()\nresponse_rate_3 = df[df['ratio_3'] == 1]['gave'].mean()\n\ndiff_1_to_2_data = response_rate_2 - response_rate_1\ndiff_2_to_3_data = response_rate_3 - response_rate_2\n\n# Convert differences in log odds to differences in probability\ncoef_ratio_1 = 0.1530\ncoef_ratio_2 = 0.2418\ncoef_ratio_3 = 0.2463\n\n# Convert log-odds to odds\nodds_ratio_1 = np.exp(coef_ratio_1)\nodds_ratio_2 = np.exp(coef_ratio_2)\nodds_ratio_3 = np.exp(coef_ratio_3)\n\n# Convert odds to probabilities\nprob_ratio_1 = odds_ratio_1 / (1 + odds_ratio_1)\nprob_ratio_2 = odds_ratio_2 / (1 + odds_ratio_2)\nprob_ratio_3 = odds_ratio_3 / (1 + odds_ratio_3)\n\n# Compute differences in probabilities\ndiff_prob_1_to_2 = prob_ratio_2 - prob_ratio_1\ndiff_prob_2_to_3 = prob_ratio_3 - prob_ratio_2\n\n\nprint('Response Rate for 1:1 Match =',response_rate_1) \nprint('Response Rate for 2:1 Match =',response_rate_2)\nprint('Response Rate for 3:1 Match =',response_rate_3)\nprint('Difference in Response Rate from 1:1 to 2:1 =',diff_1_to_2_data)\nprint('Difference in Response Rate from 2:1 to 3:1 =',diff_2_to_3_data)\nprint('Difference in Probability from 1:1 to 2:1 =',diff_prob_1_to_2)\nprint('Difference in Probability from 2:1 to 3:1 =',diff_prob_2_to_3)\n\nResponse Rate for 1:1 Match = 0.020749124225276205\nResponse Rate for 2:1 Match = 0.0226333752469912\nResponse Rate for 3:1 Match = 0.022733399227244138\nDifference in Response Rate from 1:1 to 2:1 = 0.0018842510217149944\nDifference in Response Rate from 2:1 to 3:1 = 0.00010002398025293902\nDifference in Probability from 1:1 to 2:1 = 0.02198162510978996\nDifference in Probability from 2:1 to 3:1 = 0.0011084130839175144\n\n\nDirect Data Analysis:\n\nThere is a small increase in response rate when moving from a 1:1 to a 2:1 match ratio (0.19%), indicating a slight effectiveness in increasing donations.\nThe increase from a 2:1 to a 3:1 match ratio is very minimal (0.01%), suggesting diminishing returns or nearly no additional benefit from increasing the match ratio beyond 2:1.\n\nRegression Analysis:\n\nThe regression model shows a significant relative increase (2.20%) in the probability of donating when moving from a 1:1 to a 2:1 match ratio, indicating a notable impact on donation likelihood.\nThe increase from 2:1 to 3:1 in probability (0.11%) is small, aligning with the direct data analysis that suggests minimal additional benefit from moving to even higher match ratios.\n\nThese findings suggest that while increasing the match ratio from 1:1 to 2:1 does increase the likelihood of donations, the incremental benefit of further increasing the ratio to 3:1 is very limited. This could help organizations optimize their matching strategies, potentially favoring a 2:1 ratio over higher ratios which do not appear to significantly boost donation rates beyond that point.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nThe code below is to calculate a t-test and run a bivariate linear regression of the donation amount on the treatment status.\n\n# Define the control group \ncontrol_group_amount = df[df['control'] == 1]['amount']\n\n# Define the treatment group \ntreatment_group_amount = df[df['treatment'] == 1]['amount']\n\n# Perform t-test between control and treatment groups\nt_test_result = stats.ttest_ind(control_group_amount, treatment_group_amount, equal_var=False)\n\n# Run a bivariate linear regression of donation amount on treatment status\nX_treat = sm.add_constant(df['treatment'])  # Treatment status with constant\ny_amount = df['amount']  # Donation amount\n\n# Fit the linear regression model\nlinear_model = sm.OLS(y_amount, X_treat).fit()\n\nlinear_model.summary(), t_test_result\n\n(&lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                 amount   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     3.461\n Date:                Tue, 16 Apr 2024   Prob (F-statistic):             0.0628\n Time:                        16:12:22   Log-Likelihood:            -1.7946e+05\n No. Observations:               50083   AIC:                         3.589e+05\n Df Residuals:                   50081   BIC:                         3.589e+05\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const          0.8133      0.067     12.063      0.000       0.681       0.945\n treatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n ==============================================================================\n Omnibus:                    96861.113   Durbin-Watson:                   2.008\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\n Skew:                          15.297   Prob(JB):                         0.00\n Kurtosis:                     341.269   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\",\n TtestResult(statistic=-1.9182618934467577, pvalue=0.055085665289183336, df=36216.05660774625))\n\n\n\nThe results suggest that there is a potential increase in the amount donated when individuals are in the treatment group (receiving some form of matched donation offer) compared to the control group (not receiving a matched donation offer), but this increase is not definitively proven with these tests.\nThe statistical significance is marginal, and the effect size is small, meaning that while the treatment might influence the amount given, the effect is not large.\nThis analysis is beneficial as it provides an initial understanding of the relationship between match offers and donation behavior. Further analysis might involve looking at the specific sizes of match ratios to identify which are most effective.\n\nWhat if we limit the data to just people who made a donation and repeat the previous analysis?\n\n# To limit the data to just people who made a donation, we filter the DataFrame\ndf_donors = df[df['amount'] &gt; 0]\n\n# Perform the t-test between control and treatment groups for donors only\ncontrol_group_donors = df_donors[df_donors['control'] == 1]['amount']\ntreatment_group_donors = df_donors[df_donors['treatment'] == 1]['amount']\nt_test_donors_result = stats.ttest_ind(control_group_donors, treatment_group_donors, equal_var=False)\n\n# Run a bivariate linear regression of donation amount on treatment status for donors only\nX_donors = sm.add_constant(df_donors['treatment'])  # Treatment status with constant\ny_donors_amount = df_donors['amount']  # Donation amount\n\n# Fit the linear regression model for donors\nlinear_model_donors = sm.OLS(y_donors_amount, X_donors).fit()\n\nlinear_model_donors.summary(),t_test_donors_result\n\n(&lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                 amount   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                 -0.001\n Method:                 Least Squares   F-statistic:                    0.3374\n Date:                Tue, 16 Apr 2024   Prob (F-statistic):              0.561\n Time:                        16:12:22   Log-Likelihood:                -5326.8\n No. Observations:                1034   AIC:                         1.066e+04\n Df Residuals:                    1032   BIC:                         1.067e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const         45.5403      2.423     18.792      0.000      40.785      50.296\n treatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n ==============================================================================\n Omnibus:                      587.258   Durbin-Watson:                   2.031\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\n Skew:                           2.464   Prob(JB):                         0.00\n Kurtosis:                      13.307   Cond. No.                         3.49\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\",\n TtestResult(statistic=0.5846089794983359, pvalue=0.5590471865673547, df=557.4599304243758))\n\n\nThe negative coefficient for the treatment could suggest that the treatment (receiving some form of matched donation offer) does not necessarily lead to larger donations among those who chose to donate.\n\nimport matplotlib.pyplot as plt\n\n# Histogram for the treatment group\nplt.figure(figsize=(14, 6))\n\n# Treatment histogram\nplt.subplot(1, 2, 1)\nplt.hist(treatment_group_donors, bins=30, color='orange', alpha=0.7)\nplt.axvline(treatment_group_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group Donation Amounts')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(axis='y', alpha=0.75)\nplt.text(treatment_group_donors.mean() * 1.1, plt.ylim()[1] * 0.9, f'Average: ${treatment_group_donors.mean():.2f}',\n         color='red')\n\n# Control histogram\nplt.subplot(1, 2, 2)\nplt.hist(control_group_donors, bins=30, color='skyblue', alpha=0.7)\nplt.axvline(control_group_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group Donation Amounts')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.grid(axis='y', alpha=0.75)\nplt.text(control_group_donors.mean() * 1.1, plt.ylim()[1] * 0.9, f'Average: ${control_group_donors.mean():.2f}',\n         color='red')\n\n# Show the plots\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe histogram on the left represents the treatment group, with a sample average donation amount indicated by a red dashed line.\nThe histogram on the right shows the control group, also with the sample average marked by a red dashed line.\n\nIn both histograms, most of the donations are clustered at the lower end of the scale, with fewer large donations. This is a common pattern in charitable giving, where many small donations are accompanied by a smaller number of larger gifts."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/hw1_questions.html#simulation-experiment",
    "title": "Homework1 - A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThe plot shows the cumulative average difference between the treatment and control groups over 10,000 simulations. As the number of simulations increases, the cumulative average difference begins to stabilize and approaches the true difference in probabilities (0.004, shown by the blue dashed line).\n\n# Importing the necessary libraries for simulation\nfrom scipy.stats import bernoulli\n\n# Setting the probabilities for control and treatment groups\np_control = 0.018\np_treatment = 0.022\n\nrandom_state = 12\n\n# Simulating 100,000 draws from the control distribution with a random state\ncontrol_sim = bernoulli.rvs(p_control, size=100000, random_state=random_state)\n\n# Simulating 10,000 draws from the treatment distribution with a random state\ntreatment_sim = bernoulli.rvs(p_treatment, size=10000, random_state=random_state)\n\n# Calculate the vector of 10,000 differences\n# For each of the first 10,000 elements in the control group,\n# we calculate the difference to the corresponding (by index) element in the treatment group.\n# We then calculate the cumulative average of these differences.\ndifferences = treatment_sim[:10000] - control_sim[:10000]\ncumulative_average = np.cumsum(differences) / np.arange(1, 10001)\n\n# Plotting the cumulative average of differences\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_average, color='red')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average of Difference')\nplt.title('Cumulative Average Difference Between Treatment and Control')\nplt.axhline((p_treatment - p_control), color='blue', linestyle='dashed', linewidth=1)\nplt.text(10000, (p_treatment - p_control), f'True Difference: {p_treatment - p_control:.4f}', color='blue', ha='right')\nplt.show()\n\n\n\n\n\n\n\n\nThis illustrates the Law of Large Numbers in action: as the sample size grows, the sample average becomes a more accurate estimate of the population parameter. The plot confirms that the cumulative average approaches the true difference, validating that the simulation behaves as expected according to the law.\nFrom this, we learn that even with random fluctuations in data, given enough data points, our estimates will get closer to the true underlying parameters we’re trying to measure. This reinforces the value of large sample sizes in statistical analysis for achieving reliable estimates.\n\n\nCentral Limit Theorem\nThe histograms I generated represent the distribution of the average differences between the treatment and control groups for sample sizes of 50, 200, 500, and 1000. Each histogram is based on 1000 repetitions of taking samples and calculating their average difference.\n\ndef simulate_clt(control_prob, treatment_prob, sample_sizes, num_simulations=1000):\n    plt.figure(figsize=(14, 7))\n\n    for i, sample_size in enumerate(sample_sizes, 1):\n        # Simulate the differences in means\n        control_means = [bernoulli.rvs(control_prob, size=sample_size).mean() for _ in range(num_simulations)]\n        treatment_means = [bernoulli.rvs(treatment_prob, size=sample_size).mean() for _ in range(num_simulations)]\n        differences_means = np.array(treatment_means) - np.array(control_means)\n\n        # Calculate the true difference in means\n        true_diff = treatment_prob - control_prob\n\n        # Plot the histogram of the 1000 average differences\n        plt.subplot(2, 2, i)\n        plt.hist(differences_means, bins=30, color='grey', edgecolor='black')\n        plt.axvline(true_diff, color='red', linestyle='dashed', linewidth=2)\n        plt.axvline(np.mean(differences_means), color='blue', linestyle='dashed', linewidth=1)\n        plt.title(f'Sample Size {sample_size}')\n        plt.xlabel('Average Difference')\n        plt.ylabel('Frequency')\n        plt.grid(axis='y', alpha=0.75)\n\n        # Annotation for the true difference and the sample mean difference\n        plt.text(true_diff, plt.ylim()[1] * 0.9, f'True Diff: {true_diff:.4f}', color='red', ha='center')\n        plt.text(np.mean(differences_means), plt.ylim()[1] * 0.8, f'Sample Mean: {np.mean(differences_means):.4f}', color='blue', ha='center')\n\n    plt.tight_layout()\n    plt.show()\n\n# Sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\n\n# Run the simulation and plot the histograms\nsimulate_clt(p_control, p_treatment, sample_sizes)\n\n\n\n\n\n\n\n\nInterpretation of the Histograms:\n\nSample Size 50:\n\nThe histogram shows a wide spread of the average differences, indicating high variability in the sample means.\nThe true difference (0.0040) is marked by the red dashed line, and the sample mean of the differences (blue dashed line) is close to this true difference, which shows that even at a small sample size, the average of the differences can be close to the true difference, but individual simulations may vary widely.\nZero is not in the middle of the distribution, indicating that the true difference between the control and treatment means is not zero and the effect of the treatment is consistently in one direction.\n\nSample Size 200, 500, and 1000:\n\nAs the sample size increases, the histograms become more narrow and peak closer to the true difference. This is a demonstration of the Central Limit Theorem, which states that the distribution of the sample mean will become approximately normal (bell-shaped) as the sample size increases, even if the underlying distribution is not normal.\nThe consistency of the sample mean with the true difference improves with larger sample sizes, reflecting reduced variability and increased precision in the estimate of the mean difference.\nZero moves further into the tail of the distribution as the sample size increases, confirming that it is not the center of the distribution and that there is a systematic difference between the treatment and control groups.\nThese histograms illustrate that as the sample size grows, the sampling distribution of the mean becomes more concentrated around the true mean difference, confirming the principles of the Central Limit Theorem. They also show that the treatment has a consistent effect on the probability of donation since zero is not in the center but rather in the tail of the distributions, particularly for larger sample sizes."
  },
  {
    "objectID": "projects/project1/hw2_questions.html",
    "href": "projects/project1/hw2_questions.html",
    "title": "Homework2 - Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\n\nblueprinty_data = pd.read_csv('/home/jovyan/code/MGTA 495/QUARTO_WEBSITE/data/blueprinty.csv')\n\nblueprinty_data.head(), blueprinty_data.columns\n\n(   Unnamed: 0  patents     region   age  iscustomer\n 0           1        0    Midwest  32.5           0\n 1         786        3  Southwest  37.5           0\n 2         348        4  Northwest  27.0           1\n 3         927        3  Northeast  24.5           0\n 4         830        3  Southwest  37.0           0,\n Index(['Unnamed: 0', 'patents', 'region', 'age', 'iscustomer'], dtype='object'))\n\n\nThe dataset contains the following columns:\n\nUnnamed: 0: An identifier column which we can ignore or drop.\npatents: Number of patents awarded over the last 5 years.\nregion: Regional location of the firm.\nage: Age of the firm since incorporation.\niscustomer: Indicates whether the firm uses Blueprinty’s software (1 for yes, 0 for no).\n\nNext, we’ll drop the Unnamed: 0 column as it’s not needed for our analysis, and then proceed to generate histograms and calculate means for the number of patents based on customer status.\n\n# Drop the 'Unnamed: 0' column\nblueprinty_data.drop(columns='Unnamed: 0', inplace=True)\n\n# Separate the data into two groups: customers and non-customers of Blueprinty\n\ncustomer_data = blueprinty_data[blueprinty_data['iscustomer'] == 1]\nnon_customer_data = blueprinty_data[blueprinty_data['iscustomer'] == 0]\n\n# Calculate means of patents for both groups\n\nmean_patents_customers = customer_data['patents'].mean()\nmean_patents_non_customers = non_customer_data['patents'].mean()\n\nprint('Means of patents for customers',mean_patents_customers) \n\nprint('Means of patents for non-customers',mean_patents_non_customers)\n\nMeans of patents for customers 4.091370558375634\nMeans of patents for non-customers 3.6231772831926325\n\n\nThe mean number of patents for firms that use Blueprinty’s software is approximately 4.09, while for those that do not use the software, it is about 3.62. This suggests that firms using the software might be having a slightly higher success rate in obtaining patents.\nNext, we’ll create histograms to visually compare the distribution of patents between the two groups.\n\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(8, 6))\n\nplt.hist(non_customer_data['patents'], bins=30, alpha=0.5, label='Non-Customers', color='blue')\nplt.hist(customer_data['patents'], bins=30, alpha=0.5, label='Customers', color='red')\n\nplt.title('Distribution of Patents Awarded (Customers vs Non-Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe histograms show the distribution of patents awarded to firms, comparing those that use Blueprinty’s software (red) and those that do not (blue). From the histograms, it appears that:\n\nBoth groups have a broadly similar shape in their distributions, but there is a slight shift towards higher values for customers of Blueprinty.\nThe customer group shows a bit more frequency in higher patent counts.\n\nThis visual comparison, along with the calculated means, may support the marketing claim that firms using Blueprinty’s software have a somewhat higher success rate in obtaining patents, though it should be noted that a more detailed statistical analysis would be needed to establish causality and account for potential confounders such as firm size and region. If needed, we can conduct further statistical tests or explore additional factors in the data.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nTo address this new task, we’ll explore the potential systematic differences in age and regional distribution between Blueprinty’s customers and non-customers. We’ll start by comparing the average age of the firms and then examine the regional distributions for both groups.\n\n# Calculate mean age for both groups\nmean_age_customers = customer_data['age'].mean()\nmean_age_non_customers = non_customer_data['age'].mean()\n\n# Prepare data for regional distribution comparison\nregion_distribution_customers = customer_data['region'].value_counts(normalize=True) * 100\nregion_distribution_non_customers = non_customer_data['region'].value_counts(normalize=True) * 100\n\n(mean_age_customers, mean_age_non_customers), (region_distribution_customers, region_distribution_non_customers)\n\n((24.1497461928934, 26.691481197237145),\n (region\n  Northeast    57.360406\n  Southwest    15.736041\n  South        10.152284\n  Midwest       8.629442\n  Northwest     8.121827\n  Name: proportion, dtype: float64,\n  region\n  Northeast    37.452034\n  Southwest    20.414428\n  Midwest      15.886416\n  Northwest    13.123561\n  South        13.123561\n  Name: proportion, dtype: float64))\n\n\nAge Comparison:\n\nThe average age of firms using Blueprinty’s software is about 24.15 years.\nThe average age of firms not using the software is slightly higher at around 26.69 years.\n\nThis suggests that firms using Blueprinty’s software tend to be a bit younger on average than those that do not use the software.\nRegional Distribution:\nFor Blueprinty’s customers:\n\nThe Northeast region has the highest representation at approximately 57.36%.\nOther regions like the Southwest and South have significantly lower representations.\n\nFor non-customers:\n\nThe Northeast still leads but with a lower percentage at 37.45%.\nThere is a more balanced distribution across other regions, with Southwest, Midwest, Northwest, and South more evenly spread than in the customer group.\n\nConclusion:\nThese results indicate systematic differences in both age and regional distribution between customers and non-customers. Blueprinty’s customers are generally younger and more concentrated in the Northeast compared to non-customers. This could imply regional and demographic market penetration differences or preferences that could be influencing the observed patent outcomes.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nFor a variable \\(Y\\) that follows a Poisson distribution with a mean rate of \\(\\lambda\\), the probability mass function (PMF) is given by:\n\\[\nf(Y|\\lambda) = e^{-\\lambda} \\frac{\\lambda^Y}{Y!}\n\\]\nThe likelihood \\(L(\\lambda|Y)\\) of observing the data \\(Y\\) given the parameter \\(\\lambda\\) is the product of the probabilities for all observed values \\(y_i\\) in the dataset:\n\\[\nL(\\lambda|Y) = \\prod_{i=1}^n f(y_i|\\lambda) = \\prod_{i=1}^n e^{-\\lambda} \\frac{\\lambda^{y_i}}{y_i!}\n\\]\nThis is often transformed into the log-likelihood for computational convenience, especially to avoid underflow problems with very small likelihood values. The log-likelihood \\(\\ell(\\lambda)\\) is the sum of the logs of the individual probabilities:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^n \\log \\left( e^{-\\lambda} \\frac{\\lambda^{y_i}}{y_i!} \\right)\n\\]\n\\[\n= \\sum_{i=1}^n \\left( -\\lambda + y_i \\log(\\lambda) - \\log(y_i!) \\right)\n\\]\nThe following is the Python code for the log-likelihood function for a Poisson model. This function will calculate the log-likelihood given an array 𝑌 of observed values and a parameter 𝜆.\n\nimport numpy as np\nfrom scipy.special import gammaln  # gammaln(x) computes log(x!)\n\ndef poisson_loglikelihood(lambda_, Y):\n    \"\"\"\n    Compute the log-likelihood for a Poisson model.\n    \n    Parameters:\n        lambda_ (float): The Poisson rate parameter (lambda).\n        Y (array-like): Array of observed count data.\n    \n    Returns:\n        float: The log-likelihood of the Poisson model given the data Y and rate lambda.\n    \"\"\"\n    Y = np.array(Y)  # Ensure Y is an array for vectorized operations\n    return -lambda_ * len(Y) + np.sum(Y * np.log(lambda_)) - np.sum(gammaln(Y + 1))\n\nThis code uses gammaln to efficiently compute the logarithm of the factorial, which is used in the denominator of the Poisson probability mass function. This function allows for the handling of large values of 𝑌 without overflow errors.\nTo address this task, we’ll plot the log-likelihood of observing the actual data over a range of possible values for the parameter 𝜆 (the average number of patents awarded per firm over the last 5 years). We’ll use the data from the dataset to compute the log-likelihoods.\nWe’ll:\n\nExtract the observed number of patents into an array 𝑌.\nDefine a range of 𝜆 values.\nCalculate the log-likelihood for each 𝜆 using the function we’ve defined.\nPlot these values to visualize how the log-likelihood changes with different 𝜆.\n\n\nY = blueprinty_data['patents'].values\n\n# Define a range of lambda values from 0.1 to 10, incrementing by 0.1\nlambdas = np.arange(0.1, 10, 0.1)\n\n# Calculate log-likelihoods for each lambda\nlog_likelihoods = [poisson_loglikelihood(lambda_, Y) for lambda_ in lambdas]\n\n# Plotting\nplt.figure(figsize=(8, 6))\nplt.plot(lambdas, log_likelihoods, marker='o', linestyle='-', color='b')\nplt.title('Log-Likelihood of Poisson Model for Various Lambda')\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe plot above illustrates how the log-likelihood of the Poisson model changes with different values of 𝜆, the rate parameter representing the average number of patents awarded per firm over five years. The curve shows the typical shape for a likelihood function in Poisson modeling, where there is a peak (maximum) indicating the most likely estimate of 𝜆 given the data.\nYou can observe the 𝜆 value at which the log-likelihood reaches its maximum, which provides an estimate of the average rate of patents per firm that best fits the observed data under a Poisson model assumption. This visualization helps in understanding the fit of the Poisson model to the data and in determining the parameter that maximizes the likelihood. If needed, more precise methods such as numerical optimization could be used to find the exact maximum likelihood estimate. ​\nTo confirm the estimate of \\(\\lambda\\) (denoted as \\(\\hat{\\lambda}_{MLE}\\)) for the Poisson model using the method of maximum likelihood, we can analytically solve this by taking the derivative of the log-likelihood function with respect to \\(\\lambda\\), setting it to zero, and solving for \\(\\lambda\\). Let’s walk through the mathematics of it.\nDerivative of the Log-Likelihood Function\nGiven the log-likelihood function for a Poisson distribution:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^n (-\\lambda + y_i \\log(\\lambda) - \\log(y_i!))\n\\]\nTaking the derivative with respect to \\(\\lambda\\) gives:\n\\[\n\\frac{d\\ell(\\lambda)}{d\\lambda} = \\sum_{i=1}^n \\left(-1 + \\frac{y_i}{\\lambda}\\right)\n\\]\nSetting this derivative equal to zero to find the critical points:\n\\[\n\\sum_{i=1}^n \\left(-1 + \\frac{y_i}{\\lambda}\\right) = 0\n\\]\n\\[\n-n + \\sum_{i=1}^n \\frac{y_i}{\\lambda} = 0\n\\]\n\\[\n\\frac{1}{\\lambda} \\sum_{i=1}^n y_i = n\n\\]\n\\[\n\\lambda = \\frac{\\sum_{i=1}^n y_i}{n}\n\\]\nThis simplifies to:\n\\[\n\\hat{\\lambda}_{MLE} = \\bar{Y}\n\\]\nwhere \\(\\bar{Y}\\) is the sample mean of the observed values. This result aligns with our intuition and the properties of the Poisson distribution, where the mean (and variance) is \\(\\lambda\\).\nLet’s compute this using the data we have to verify if the maximum likelihood estimate (MLE) \\(\\lambda\\) indeed equals the mean number of patents per firm.\n\nlambda_mle = Y.mean()\n\nprint('Maximum likelihood estimate (MLE) is ',lambda_mle)\n\nMaximum likelihood estimate (MLE) is  3.6846666666666668\n\n\nThe maximum likelihood estimate (MLE) for 𝜆 based on our data is approximately 3.685. This value represents the average number of patents per firm over the last five years, which is consistent with our earlier computation and the theoretical result that the MLE for a Poisson distribution’s parameter 𝜆 is the sample mean (𝑌‾). This confirms the fit of the model to our data and the validity of using a Poisson model for this analysis.\nTo find the maximum likelihood estimate (MLE) for 𝜆 using numerical optimization in Python, we can use the minimize function from the scipy.optimize library. Since minimize seeks to find the minimum of a function, and we’re interested in maximizing the log-likelihood, we will minimize the negative of the log-likelihood.\nHere’s how we can achieve this:\n\nDefine the negative of the log-likelihood function for the Poisson model.\nUse the minimize function to find the value of 𝜆 that minimizes this negative log-likelihood.\nProvide a reasonable initial guess for 𝜆 (such as the sample mean) and bounds to ensure the optimization stays within plausible values.\n\n\nfrom scipy.optimize import minimize\n\ndef negative_poisson_loglikelihood(lambda_, Y):\n    \"\"\"\n    Compute the negative log-likelihood for a Poisson model.\n    \n    Parameters:\n        lambda_ (float): The Poisson rate parameter (lambda).\n        Y (array-like): Array of observed count data.\n    \n    Returns:\n        float: The negative log-likelihood of the Poisson model given the data Y and rate lambda.\n    \"\"\"\n    # Ensure lambda is a scalar for operations\n    lambda_ = lambda_[0]\n    return -(-lambda_ * len(Y) + np.sum(Y * np.log(lambda_)) - np.sum(gammaln(Y + 1)))\n\n# Initial guess for lambda (using the sample mean)\ninitial_lambda = [Y.mean()]\n\n# Optimization to find the MLE of lambda\nresult = minimize(negative_poisson_loglikelihood, initial_lambda, args=(Y,), bounds=[(0.1, None)])\n\n# Resulting MLE for lambda\nlambda_mle_optimized = result.x\n\nresult, lambda_mle_optimized\n\n(  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL\n   success: True\n    status: 0\n       fun: 3367.6837722350956\n         x: [ 3.685e+00]\n       nit: 1\n       jac: [ 0.000e+00]\n      nfev: 10\n      njev: 5\n  hess_inv: &lt;1x1 LbfgsInvHessProduct with dtype=float64&gt;,\n array([3.68466671]))\n\n\nThe optimization process successfully found the maximum likelihood estimate (MLE) for 𝜆, and the result is approximately 3.685, which matches the sample mean of the observed data as well as the analytical result we computed earlier. This confirms that the numerical optimization approach using minimize from scipy.optimize is consistent with the theoretical expectations for the Poisson model.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nTo solve the problem as outlined, we’ll update the log-likelihood function for a Poisson regression model. In this model, the expected count \\(\\lambda_i\\) for each observation is expressed as an exponential function of a linear combination of covariates. This ensures that \\(\\lambda_i\\) remains positive.\nPoisson Regression Log-Likelihood\nThe log-likelihood for a Poisson regression, where \\(Y_i\\) follows a Poisson distribution with parameter \\(\\lambda_i = \\exp(X'_i\\beta)\\), is given by:\n\\[\n\\ell(\\beta) = \\sum_{i=1}^n \\left( -\\exp(X'_i\\beta) + Y_i(X'_i\\beta) - \\log(Y_i!) \\right)\n\\]\nWhere:\n\n\\(X_i\\) is a vector of covariates for the ith observation (including intercept, if applicable).\n\\(\\beta\\) is the vector of coefficients to be estimated.\n\\(Y_i\\) is the observed count of patents for the ith firm.\n\nWe will code this function in Python, using numpy for matrix operations. We will also handle the creation of dummy variables for categorical covariates such as region and prepare the data accordingly.\nLet’s first prepare our dataset by encoding categorical variables and then implement the log-likelihood function.\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import gammaln\n\n# Encode categorical variables and add an intercept term\nblueprinty_data_encoded = pd.get_dummies(blueprinty_data, columns=['region'], drop_first=True)\nblueprinty_data_encoded['intercept'] = 1\n\n# Add age squared as a feature\nblueprinty_data_encoded['age_squared'] = blueprinty_data_encoded['age'] ** 2\n\n# Prepare X and Y matrices, ensuring all are float type for consistency\nfeatures = ['intercept', 'age', 'age_squared', 'iscustomer'] + [col for col in blueprinty_data_encoded.columns if 'region_' in col]\nX = blueprinty_data_encoded[features].astype(float).values  # Cast to float\nY = blueprinty_data_encoded['patents'].astype(float).values  # Ensure Y is also float\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta, dtype=np.float64)  # Convert beta to float64 to ensure type consistency\n    eta = np.dot(X, beta)  # Compute the linear combination using dot product\n    # Clip eta to prevent overflow\n    eta = np.clip(eta, -100, 100)\n\n    # Calculate the Poisson log-likelihood\n    log_likelihood = -np.sum(np.exp(eta)) + np.sum(Y * eta) - np.sum(gammaln(Y + 1))\n    return log_likelihood\n\n# Initialize beta with zeros\ninitial_beta = np.zeros(X.shape[1])\n\ndef negative_poisson_regression_loglikelihood(beta, Y, X):\n    return -poisson_regression_loglikelihood(beta, Y, X)\n\n# Compute log-likelihood with the initial beta\nlog_likelihood = poisson_regression_loglikelihood(initial_beta, Y, X)\nprint(\"Log-likelihood with initial beta:\", log_likelihood)\n\nLog-likelihood with initial beta: -6548.8869900694435\n\n\nThe log-likelihood function for our Poisson regression model has been successfully implemented and tested with an initial guess for the coefficients 𝛽. The initial log-likelihood value using a beta vector of zeros is approximately -6548.89.\nNow, to find the maximum likelihood estimates (MLEs) of the coefficients 𝛽 using numerical optimization. We’ll use the minimize function from scipy.optimize to find the maximum likelihood estimates (MLEs) for the vector of coefficients 𝛽 in our Poisson regression model. Additionally, we will calculate the Hessian at the optimal solution to find the standard errors of the estimated coefficients.\nLet’s proceed with these steps:\n\nUse minimize with the method that allows for Hessian calculation.\nCalculate the standard errors of the coefficients using the inverse of the Hessian matrix.\nPresent the results in a table with coefficients and their standard errors.\n\nWe will use the L-BFGS-B method because it supports bounds and is efficient for a large number of parameters. We will also explicitly request the Hessian matrix from the optimization function.\n\n# Scale age and age squared to improve numerical stability\nfrom sklearn.preprocessing import StandardScaler\n\n# Initialize a scaler\nscaler = StandardScaler()\n\n# Fit the scaler to the age and age squared and transform\nX_scaled = X.copy()\nX_scaled[:, 1:3] = scaler.fit_transform(X[:, 1:3])\n\n# Run the optimization with scaled covariates and improved initial guess\ninitial_beta_scaled = np.zeros(X_scaled.shape[1])\n\nopt_result_scaled = minimize(negative_poisson_regression_loglikelihood, initial_beta_scaled, args=(Y, X_scaled), method='L-BFGS-B', options={'disp': True})\n\n# Check if the optimization was successful and calculate standard errors if so\nif opt_result_scaled.success:\n    estimated_beta_scaled = opt_result_scaled.x\n    hessian_inv_scaled = opt_result_scaled.hess_inv.todense()\n    standard_errors_scaled = np.sqrt(np.diag(hessian_inv_scaled))\nelse:\n    estimated_beta_scaled, standard_errors_scaled = None, None\n    print(\"Optimization failed:\", opt_result_scaled.message)\n\nestimated_beta_scaled, standard_errors_scaled\n\n(array([ 1.2154516 ,  1.04643413, -1.1408189 ,  0.11817246,  0.09855963,\n        -0.02005261,  0.05715704,  0.05127718]),\n array([0.51947864, 1.96081248, 1.91411578, 1.0137265 , 0.71785267,\n        0.98707176, 0.87758848, 0.60700405]))\n\n\nThe optimization process has now successfully converged with scaled covariate data, providing a stable set of estimated coefficients \\(\\beta\\) and calculated standard errors. Here are the results presented in a table format:\nTable of Coefficients and Standard Errors\n\n\n\nVariable\nCoefficient Estimate\nStandard Error\n\n\n\n\nIntercept\n1.215\n0.517\n\n\nAge (scaled)\n1.046\n1.956\n\n\nAge Squared (scaled)\n-1.141\n1.909\n\n\nCustomer Status\n0.118\n1.015\n\n\nRegion_Northeast\n0.099\n0.712\n\n\nRegion_South\n-0.020\n0.986\n\n\nRegion_Southwest\n0.057\n0.877\n\n\nRegion_Northwest\n0.051\n0.608\n\n\n\nThese results provide insights into the effects of the covariates on the number of patents awarded to firms, where:\n\nIntercept: Base effect when all predictors are zero.\nAge: Positive coefficient suggests that an increase in age tends to increase the log count of patents.\nAge Squared: Negative coefficient for age squared implies a diminishing return effect, where increasing age past a certain point decreases the count.\nCustomer Status: Being a customer of Blueprinty shows a positive (but small) effect on the count of patents.\nRegions: Various regions show different effects relative to the baseline region (which is omitted due to dummy variable coding).\n\nStandard errors indicate the precision of the estimates; larger standard errors suggest less precise estimates. These results can be used to make statistical inferences about the significance and impact of each factor on patent awards.\nTo validate our results, we can use the statsmodels library’s Generalized Linear Models (GLM) functionality to fit a Poisson regression model to the data. This will also give us an opportunity to compare the coefficients and standard errors from a well-established statistical method.\n\nimport statsmodels.api as sm\n\n# Fit GLM model with Poisson family\nglm_poisson = sm.GLM(Y, X_scaled, family=sm.families.Poisson())\nglm_results = glm_poisson.fit()\n\n# Display the results: coefficients and standard errors\nglm_coefficients = glm_results.params\nglm_standard_errors = glm_results.bse\nglm_summary = glm_results.summary()\n\nglm_coefficients, glm_standard_errors, glm_summary\n\n(array([ 1.21543811,  1.04645998, -1.14084543,  0.11811441,  0.09859598,\n        -0.02009423,  0.05717196,  0.05134696]),\n array([0.0364255 , 0.10048749, 0.10249457, 0.03892044, 0.04200704,\n        0.05378329, 0.05267573, 0.04721241]),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                  Generalized Linear Model Regression Results                  \n ==============================================================================\n Dep. Variable:                      y   No. Observations:                 1500\n Model:                            GLM   Df Residuals:                     1492\n Model Family:                 Poisson   Df Model:                            7\n Link Function:                    Log   Scale:                          1.0000\n Method:                          IRLS   Log-Likelihood:                -3275.9\n Date:                Wed, 01 May 2024   Deviance:                       2178.8\n Time:                        06:35:59   Pearson chi2:                 2.11e+03\n No. Iterations:                     5   Pseudo R-squ. (CS):             0.1152\n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const          1.2154      0.036     33.368      0.000       1.144       1.287\n x1             1.0465      0.100     10.414      0.000       0.850       1.243\n x2            -1.1408      0.102    -11.131      0.000      -1.342      -0.940\n x3             0.1181      0.039      3.035      0.002       0.042       0.194\n x4             0.0986      0.042      2.347      0.019       0.016       0.181\n x5            -0.0201      0.054     -0.374      0.709      -0.126       0.085\n x6             0.0572      0.053      1.085      0.278      -0.046       0.160\n x7             0.0513      0.047      1.088      0.277      -0.041       0.144\n ==============================================================================\n \"\"\")\n\n\nThe GLM results from the statsmodels package provide coefficients and standard errors that align closely with the ones obtained from our custom optimization method. Here’s a summary of the findings:\nCoefficients and Standard Errors (Statsmodels GLM)\nHere is the table of coefficients and standard errors from a Generalized Linear Model (GLM) using the Statsmodels library:\n\n\n\nVariable\nCoefficient Estimate\nStandard Error\n\n\n\n\nIntercept\n1.215\n0.036\n\n\nAge (scaled)\n1.046\n0.100\n\n\nAge Squared (scaled)\n-1.141\n0.102\n\n\nCustomer Status\n0.118\n0.039\n\n\nRegion_Northeast\n0.098\n0.042\n\n\nRegion_South\n-0.020\n0.054\n\n\nRegion_Southwest\n0.057\n0.053\n\n\nRegion_Northwest\n0.051\n0.047\n\n\n\nThe coefficients estimated by the statsmodels GLM are quite similar to those from the scipy.optimize function, suggesting consistency across methods. Notably, the standard errors from the GLM are generally smaller, which might be due to differences in how the Hessian is calculated or the numerical stability offered by the statsmodels framework.\nThese results confirm the validity of our earlier optimization and highlight the potential influences of firm age, customer status, and regional location on the number of patents awarded. Such analyses can be crucial for Blueprinty to understand and possibly predict patent application success across different demographics and regions.\nThe results from the Poisson regression model provide insightful interpretations regarding the effect of various factors, including the use of Blueprinty’s software, on the number of patents awarded to engineering firms. Here are the key interpretations based on the coefficients obtained:\n\n\n\nIntercept (Base Effect):\n\nThe coefficient for the intercept is significantly positive, suggesting a base rate of patent awards when all other variables are zero.\n\nAge and Age Squared:\n\nThe positive coefficient for age indicates that, initially, as firms get older, they tend to receive more patents.\nThe negative coefficient for age squared suggests a diminishing return effect: as firms continue to age beyond a certain point, the increase in patents awarded slows down and eventually may decrease. This could reflect the lifecycle of firm innovation or shifts in focus as firms mature.\n\nCustomer Status (Use of Blueprinty’s Software):\n\nThe coefficient for customer status is positive and statistically significant (p-value &lt; 0.05), indicating that firms using Blueprinty’s software tend to have a higher number of patents awarded compared to those that do not use the software.\nThis result supports Blueprinty’s marketing claim that using their software is associated with higher patent success.\n\nRegional Variables:\n\nThe coefficients for regions (compared to a baseline region not included in the model to avoid dummy variable trap) show some variation in patent awards across different regions, with some coefficients being positive and others negative or statistically insignificant. This indicates regional differences in patent award rates, which could be influenced by local economic conditions, regional innovation trends, or the presence of research institutions.\n\n\nConclusions\n\nThe positive and significant effect of using Blueprinty’s software on the number of patents awarded supports the claim that the software potentially enhances patent application success. This effect remains even after controlling for firm age and regional differences.\nThe analysis also highlights the impact of firm age on patent success, with a peak effect after which the benefits decrease. This could inform Blueprinty’s targeting strategy, perhaps focusing more on firms at certain stages of their lifecycle.\nRegional variations suggest that market conditions or regional characteristics might also play a role in patent success, which could be important for regional marketing strategies.\n\nOverall, these results suggest that Blueprinty’s software is indeed associated with an increase in patent awards, providing empirical support for the marketing claims. This information could be very valuable for Blueprinty in demonstrating the effectiveness of their software to current and potential customers, and in refining their product development and marketing strategies based on the characteristics of the firms that benefit the most."
  },
  {
    "objectID": "projects/project1/hw2_questions.html#blueprinty-case-study",
    "href": "projects/project1/hw2_questions.html#blueprinty-case-study",
    "title": "Homework2 - Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\n\nblueprinty_data = pd.read_csv('/home/jovyan/code/MGTA 495/QUARTO_WEBSITE/data/blueprinty.csv')\n\nblueprinty_data.head(), blueprinty_data.columns\n\n(   Unnamed: 0  patents     region   age  iscustomer\n 0           1        0    Midwest  32.5           0\n 1         786        3  Southwest  37.5           0\n 2         348        4  Northwest  27.0           1\n 3         927        3  Northeast  24.5           0\n 4         830        3  Southwest  37.0           0,\n Index(['Unnamed: 0', 'patents', 'region', 'age', 'iscustomer'], dtype='object'))\n\n\nThe dataset contains the following columns:\n\nUnnamed: 0: An identifier column which we can ignore or drop.\npatents: Number of patents awarded over the last 5 years.\nregion: Regional location of the firm.\nage: Age of the firm since incorporation.\niscustomer: Indicates whether the firm uses Blueprinty’s software (1 for yes, 0 for no).\n\nNext, we’ll drop the Unnamed: 0 column as it’s not needed for our analysis, and then proceed to generate histograms and calculate means for the number of patents based on customer status.\n\n# Drop the 'Unnamed: 0' column\nblueprinty_data.drop(columns='Unnamed: 0', inplace=True)\n\n# Separate the data into two groups: customers and non-customers of Blueprinty\n\ncustomer_data = blueprinty_data[blueprinty_data['iscustomer'] == 1]\nnon_customer_data = blueprinty_data[blueprinty_data['iscustomer'] == 0]\n\n# Calculate means of patents for both groups\n\nmean_patents_customers = customer_data['patents'].mean()\nmean_patents_non_customers = non_customer_data['patents'].mean()\n\nprint('Means of patents for customers',mean_patents_customers) \n\nprint('Means of patents for non-customers',mean_patents_non_customers)\n\nMeans of patents for customers 4.091370558375634\nMeans of patents for non-customers 3.6231772831926325\n\n\nThe mean number of patents for firms that use Blueprinty’s software is approximately 4.09, while for those that do not use the software, it is about 3.62. This suggests that firms using the software might be having a slightly higher success rate in obtaining patents.\nNext, we’ll create histograms to visually compare the distribution of patents between the two groups.\n\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(8, 6))\n\nplt.hist(non_customer_data['patents'], bins=30, alpha=0.5, label='Non-Customers', color='blue')\nplt.hist(customer_data['patents'], bins=30, alpha=0.5, label='Customers', color='red')\n\nplt.title('Distribution of Patents Awarded (Customers vs Non-Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe histograms show the distribution of patents awarded to firms, comparing those that use Blueprinty’s software (red) and those that do not (blue). From the histograms, it appears that:\n\nBoth groups have a broadly similar shape in their distributions, but there is a slight shift towards higher values for customers of Blueprinty.\nThe customer group shows a bit more frequency in higher patent counts.\n\nThis visual comparison, along with the calculated means, may support the marketing claim that firms using Blueprinty’s software have a somewhat higher success rate in obtaining patents, though it should be noted that a more detailed statistical analysis would be needed to establish causality and account for potential confounders such as firm size and region. If needed, we can conduct further statistical tests or explore additional factors in the data.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nTo address this new task, we’ll explore the potential systematic differences in age and regional distribution between Blueprinty’s customers and non-customers. We’ll start by comparing the average age of the firms and then examine the regional distributions for both groups.\n\n# Calculate mean age for both groups\nmean_age_customers = customer_data['age'].mean()\nmean_age_non_customers = non_customer_data['age'].mean()\n\n# Prepare data for regional distribution comparison\nregion_distribution_customers = customer_data['region'].value_counts(normalize=True) * 100\nregion_distribution_non_customers = non_customer_data['region'].value_counts(normalize=True) * 100\n\n(mean_age_customers, mean_age_non_customers), (region_distribution_customers, region_distribution_non_customers)\n\n((24.1497461928934, 26.691481197237145),\n (region\n  Northeast    57.360406\n  Southwest    15.736041\n  South        10.152284\n  Midwest       8.629442\n  Northwest     8.121827\n  Name: proportion, dtype: float64,\n  region\n  Northeast    37.452034\n  Southwest    20.414428\n  Midwest      15.886416\n  Northwest    13.123561\n  South        13.123561\n  Name: proportion, dtype: float64))\n\n\nAge Comparison:\n\nThe average age of firms using Blueprinty’s software is about 24.15 years.\nThe average age of firms not using the software is slightly higher at around 26.69 years.\n\nThis suggests that firms using Blueprinty’s software tend to be a bit younger on average than those that do not use the software.\nRegional Distribution:\nFor Blueprinty’s customers:\n\nThe Northeast region has the highest representation at approximately 57.36%.\nOther regions like the Southwest and South have significantly lower representations.\n\nFor non-customers:\n\nThe Northeast still leads but with a lower percentage at 37.45%.\nThere is a more balanced distribution across other regions, with Southwest, Midwest, Northwest, and South more evenly spread than in the customer group.\n\nConclusion:\nThese results indicate systematic differences in both age and regional distribution between customers and non-customers. Blueprinty’s customers are generally younger and more concentrated in the Northeast compared to non-customers. This could imply regional and demographic market penetration differences or preferences that could be influencing the observed patent outcomes.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nFor a variable \\(Y\\) that follows a Poisson distribution with a mean rate of \\(\\lambda\\), the probability mass function (PMF) is given by:\n\\[\nf(Y|\\lambda) = e^{-\\lambda} \\frac{\\lambda^Y}{Y!}\n\\]\nThe likelihood \\(L(\\lambda|Y)\\) of observing the data \\(Y\\) given the parameter \\(\\lambda\\) is the product of the probabilities for all observed values \\(y_i\\) in the dataset:\n\\[\nL(\\lambda|Y) = \\prod_{i=1}^n f(y_i|\\lambda) = \\prod_{i=1}^n e^{-\\lambda} \\frac{\\lambda^{y_i}}{y_i!}\n\\]\nThis is often transformed into the log-likelihood for computational convenience, especially to avoid underflow problems with very small likelihood values. The log-likelihood \\(\\ell(\\lambda)\\) is the sum of the logs of the individual probabilities:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^n \\log \\left( e^{-\\lambda} \\frac{\\lambda^{y_i}}{y_i!} \\right)\n\\]\n\\[\n= \\sum_{i=1}^n \\left( -\\lambda + y_i \\log(\\lambda) - \\log(y_i!) \\right)\n\\]\nThe following is the Python code for the log-likelihood function for a Poisson model. This function will calculate the log-likelihood given an array 𝑌 of observed values and a parameter 𝜆.\n\nimport numpy as np\nfrom scipy.special import gammaln  # gammaln(x) computes log(x!)\n\ndef poisson_loglikelihood(lambda_, Y):\n    \"\"\"\n    Compute the log-likelihood for a Poisson model.\n    \n    Parameters:\n        lambda_ (float): The Poisson rate parameter (lambda).\n        Y (array-like): Array of observed count data.\n    \n    Returns:\n        float: The log-likelihood of the Poisson model given the data Y and rate lambda.\n    \"\"\"\n    Y = np.array(Y)  # Ensure Y is an array for vectorized operations\n    return -lambda_ * len(Y) + np.sum(Y * np.log(lambda_)) - np.sum(gammaln(Y + 1))\n\nThis code uses gammaln to efficiently compute the logarithm of the factorial, which is used in the denominator of the Poisson probability mass function. This function allows for the handling of large values of 𝑌 without overflow errors.\nTo address this task, we’ll plot the log-likelihood of observing the actual data over a range of possible values for the parameter 𝜆 (the average number of patents awarded per firm over the last 5 years). We’ll use the data from the dataset to compute the log-likelihoods.\nWe’ll:\n\nExtract the observed number of patents into an array 𝑌.\nDefine a range of 𝜆 values.\nCalculate the log-likelihood for each 𝜆 using the function we’ve defined.\nPlot these values to visualize how the log-likelihood changes with different 𝜆.\n\n\nY = blueprinty_data['patents'].values\n\n# Define a range of lambda values from 0.1 to 10, incrementing by 0.1\nlambdas = np.arange(0.1, 10, 0.1)\n\n# Calculate log-likelihoods for each lambda\nlog_likelihoods = [poisson_loglikelihood(lambda_, Y) for lambda_ in lambdas]\n\n# Plotting\nplt.figure(figsize=(8, 6))\nplt.plot(lambdas, log_likelihoods, marker='o', linestyle='-', color='b')\nplt.title('Log-Likelihood of Poisson Model for Various Lambda')\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe plot above illustrates how the log-likelihood of the Poisson model changes with different values of 𝜆, the rate parameter representing the average number of patents awarded per firm over five years. The curve shows the typical shape for a likelihood function in Poisson modeling, where there is a peak (maximum) indicating the most likely estimate of 𝜆 given the data.\nYou can observe the 𝜆 value at which the log-likelihood reaches its maximum, which provides an estimate of the average rate of patents per firm that best fits the observed data under a Poisson model assumption. This visualization helps in understanding the fit of the Poisson model to the data and in determining the parameter that maximizes the likelihood. If needed, more precise methods such as numerical optimization could be used to find the exact maximum likelihood estimate. ​\nTo confirm the estimate of \\(\\lambda\\) (denoted as \\(\\hat{\\lambda}_{MLE}\\)) for the Poisson model using the method of maximum likelihood, we can analytically solve this by taking the derivative of the log-likelihood function with respect to \\(\\lambda\\), setting it to zero, and solving for \\(\\lambda\\). Let’s walk through the mathematics of it.\nDerivative of the Log-Likelihood Function\nGiven the log-likelihood function for a Poisson distribution:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^n (-\\lambda + y_i \\log(\\lambda) - \\log(y_i!))\n\\]\nTaking the derivative with respect to \\(\\lambda\\) gives:\n\\[\n\\frac{d\\ell(\\lambda)}{d\\lambda} = \\sum_{i=1}^n \\left(-1 + \\frac{y_i}{\\lambda}\\right)\n\\]\nSetting this derivative equal to zero to find the critical points:\n\\[\n\\sum_{i=1}^n \\left(-1 + \\frac{y_i}{\\lambda}\\right) = 0\n\\]\n\\[\n-n + \\sum_{i=1}^n \\frac{y_i}{\\lambda} = 0\n\\]\n\\[\n\\frac{1}{\\lambda} \\sum_{i=1}^n y_i = n\n\\]\n\\[\n\\lambda = \\frac{\\sum_{i=1}^n y_i}{n}\n\\]\nThis simplifies to:\n\\[\n\\hat{\\lambda}_{MLE} = \\bar{Y}\n\\]\nwhere \\(\\bar{Y}\\) is the sample mean of the observed values. This result aligns with our intuition and the properties of the Poisson distribution, where the mean (and variance) is \\(\\lambda\\).\nLet’s compute this using the data we have to verify if the maximum likelihood estimate (MLE) \\(\\lambda\\) indeed equals the mean number of patents per firm.\n\nlambda_mle = Y.mean()\n\nprint('Maximum likelihood estimate (MLE) is ',lambda_mle)\n\nMaximum likelihood estimate (MLE) is  3.6846666666666668\n\n\nThe maximum likelihood estimate (MLE) for 𝜆 based on our data is approximately 3.685. This value represents the average number of patents per firm over the last five years, which is consistent with our earlier computation and the theoretical result that the MLE for a Poisson distribution’s parameter 𝜆 is the sample mean (𝑌‾). This confirms the fit of the model to our data and the validity of using a Poisson model for this analysis.\nTo find the maximum likelihood estimate (MLE) for 𝜆 using numerical optimization in Python, we can use the minimize function from the scipy.optimize library. Since minimize seeks to find the minimum of a function, and we’re interested in maximizing the log-likelihood, we will minimize the negative of the log-likelihood.\nHere’s how we can achieve this:\n\nDefine the negative of the log-likelihood function for the Poisson model.\nUse the minimize function to find the value of 𝜆 that minimizes this negative log-likelihood.\nProvide a reasonable initial guess for 𝜆 (such as the sample mean) and bounds to ensure the optimization stays within plausible values.\n\n\nfrom scipy.optimize import minimize\n\ndef negative_poisson_loglikelihood(lambda_, Y):\n    \"\"\"\n    Compute the negative log-likelihood for a Poisson model.\n    \n    Parameters:\n        lambda_ (float): The Poisson rate parameter (lambda).\n        Y (array-like): Array of observed count data.\n    \n    Returns:\n        float: The negative log-likelihood of the Poisson model given the data Y and rate lambda.\n    \"\"\"\n    # Ensure lambda is a scalar for operations\n    lambda_ = lambda_[0]\n    return -(-lambda_ * len(Y) + np.sum(Y * np.log(lambda_)) - np.sum(gammaln(Y + 1)))\n\n# Initial guess for lambda (using the sample mean)\ninitial_lambda = [Y.mean()]\n\n# Optimization to find the MLE of lambda\nresult = minimize(negative_poisson_loglikelihood, initial_lambda, args=(Y,), bounds=[(0.1, None)])\n\n# Resulting MLE for lambda\nlambda_mle_optimized = result.x\n\nresult, lambda_mle_optimized\n\n(  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL\n   success: True\n    status: 0\n       fun: 3367.6837722350956\n         x: [ 3.685e+00]\n       nit: 1\n       jac: [ 0.000e+00]\n      nfev: 10\n      njev: 5\n  hess_inv: &lt;1x1 LbfgsInvHessProduct with dtype=float64&gt;,\n array([3.68466671]))\n\n\nThe optimization process successfully found the maximum likelihood estimate (MLE) for 𝜆, and the result is approximately 3.685, which matches the sample mean of the observed data as well as the analytical result we computed earlier. This confirms that the numerical optimization approach using minimize from scipy.optimize is consistent with the theoretical expectations for the Poisson model.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nTo solve the problem as outlined, we’ll update the log-likelihood function for a Poisson regression model. In this model, the expected count \\(\\lambda_i\\) for each observation is expressed as an exponential function of a linear combination of covariates. This ensures that \\(\\lambda_i\\) remains positive.\nPoisson Regression Log-Likelihood\nThe log-likelihood for a Poisson regression, where \\(Y_i\\) follows a Poisson distribution with parameter \\(\\lambda_i = \\exp(X'_i\\beta)\\), is given by:\n\\[\n\\ell(\\beta) = \\sum_{i=1}^n \\left( -\\exp(X'_i\\beta) + Y_i(X'_i\\beta) - \\log(Y_i!) \\right)\n\\]\nWhere:\n\n\\(X_i\\) is a vector of covariates for the ith observation (including intercept, if applicable).\n\\(\\beta\\) is the vector of coefficients to be estimated.\n\\(Y_i\\) is the observed count of patents for the ith firm.\n\nWe will code this function in Python, using numpy for matrix operations. We will also handle the creation of dummy variables for categorical covariates such as region and prepare the data accordingly.\nLet’s first prepare our dataset by encoding categorical variables and then implement the log-likelihood function.\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import gammaln\n\n# Encode categorical variables and add an intercept term\nblueprinty_data_encoded = pd.get_dummies(blueprinty_data, columns=['region'], drop_first=True)\nblueprinty_data_encoded['intercept'] = 1\n\n# Add age squared as a feature\nblueprinty_data_encoded['age_squared'] = blueprinty_data_encoded['age'] ** 2\n\n# Prepare X and Y matrices, ensuring all are float type for consistency\nfeatures = ['intercept', 'age', 'age_squared', 'iscustomer'] + [col for col in blueprinty_data_encoded.columns if 'region_' in col]\nX = blueprinty_data_encoded[features].astype(float).values  # Cast to float\nY = blueprinty_data_encoded['patents'].astype(float).values  # Ensure Y is also float\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.array(beta, dtype=np.float64)  # Convert beta to float64 to ensure type consistency\n    eta = np.dot(X, beta)  # Compute the linear combination using dot product\n    # Clip eta to prevent overflow\n    eta = np.clip(eta, -100, 100)\n\n    # Calculate the Poisson log-likelihood\n    log_likelihood = -np.sum(np.exp(eta)) + np.sum(Y * eta) - np.sum(gammaln(Y + 1))\n    return log_likelihood\n\n# Initialize beta with zeros\ninitial_beta = np.zeros(X.shape[1])\n\ndef negative_poisson_regression_loglikelihood(beta, Y, X):\n    return -poisson_regression_loglikelihood(beta, Y, X)\n\n# Compute log-likelihood with the initial beta\nlog_likelihood = poisson_regression_loglikelihood(initial_beta, Y, X)\nprint(\"Log-likelihood with initial beta:\", log_likelihood)\n\nLog-likelihood with initial beta: -6548.8869900694435\n\n\nThe log-likelihood function for our Poisson regression model has been successfully implemented and tested with an initial guess for the coefficients 𝛽. The initial log-likelihood value using a beta vector of zeros is approximately -6548.89.\nNow, to find the maximum likelihood estimates (MLEs) of the coefficients 𝛽 using numerical optimization. We’ll use the minimize function from scipy.optimize to find the maximum likelihood estimates (MLEs) for the vector of coefficients 𝛽 in our Poisson regression model. Additionally, we will calculate the Hessian at the optimal solution to find the standard errors of the estimated coefficients.\nLet’s proceed with these steps:\n\nUse minimize with the method that allows for Hessian calculation.\nCalculate the standard errors of the coefficients using the inverse of the Hessian matrix.\nPresent the results in a table with coefficients and their standard errors.\n\nWe will use the L-BFGS-B method because it supports bounds and is efficient for a large number of parameters. We will also explicitly request the Hessian matrix from the optimization function.\n\n# Scale age and age squared to improve numerical stability\nfrom sklearn.preprocessing import StandardScaler\n\n# Initialize a scaler\nscaler = StandardScaler()\n\n# Fit the scaler to the age and age squared and transform\nX_scaled = X.copy()\nX_scaled[:, 1:3] = scaler.fit_transform(X[:, 1:3])\n\n# Run the optimization with scaled covariates and improved initial guess\ninitial_beta_scaled = np.zeros(X_scaled.shape[1])\n\nopt_result_scaled = minimize(negative_poisson_regression_loglikelihood, initial_beta_scaled, args=(Y, X_scaled), method='L-BFGS-B', options={'disp': True})\n\n# Check if the optimization was successful and calculate standard errors if so\nif opt_result_scaled.success:\n    estimated_beta_scaled = opt_result_scaled.x\n    hessian_inv_scaled = opt_result_scaled.hess_inv.todense()\n    standard_errors_scaled = np.sqrt(np.diag(hessian_inv_scaled))\nelse:\n    estimated_beta_scaled, standard_errors_scaled = None, None\n    print(\"Optimization failed:\", opt_result_scaled.message)\n\nestimated_beta_scaled, standard_errors_scaled\n\n(array([ 1.2154516 ,  1.04643413, -1.1408189 ,  0.11817246,  0.09855963,\n        -0.02005261,  0.05715704,  0.05127718]),\n array([0.51947864, 1.96081248, 1.91411578, 1.0137265 , 0.71785267,\n        0.98707176, 0.87758848, 0.60700405]))\n\n\nThe optimization process has now successfully converged with scaled covariate data, providing a stable set of estimated coefficients \\(\\beta\\) and calculated standard errors. Here are the results presented in a table format:\nTable of Coefficients and Standard Errors\n\n\n\nVariable\nCoefficient Estimate\nStandard Error\n\n\n\n\nIntercept\n1.215\n0.517\n\n\nAge (scaled)\n1.046\n1.956\n\n\nAge Squared (scaled)\n-1.141\n1.909\n\n\nCustomer Status\n0.118\n1.015\n\n\nRegion_Northeast\n0.099\n0.712\n\n\nRegion_South\n-0.020\n0.986\n\n\nRegion_Southwest\n0.057\n0.877\n\n\nRegion_Northwest\n0.051\n0.608\n\n\n\nThese results provide insights into the effects of the covariates on the number of patents awarded to firms, where:\n\nIntercept: Base effect when all predictors are zero.\nAge: Positive coefficient suggests that an increase in age tends to increase the log count of patents.\nAge Squared: Negative coefficient for age squared implies a diminishing return effect, where increasing age past a certain point decreases the count.\nCustomer Status: Being a customer of Blueprinty shows a positive (but small) effect on the count of patents.\nRegions: Various regions show different effects relative to the baseline region (which is omitted due to dummy variable coding).\n\nStandard errors indicate the precision of the estimates; larger standard errors suggest less precise estimates. These results can be used to make statistical inferences about the significance and impact of each factor on patent awards.\nTo validate our results, we can use the statsmodels library’s Generalized Linear Models (GLM) functionality to fit a Poisson regression model to the data. This will also give us an opportunity to compare the coefficients and standard errors from a well-established statistical method.\n\nimport statsmodels.api as sm\n\n# Fit GLM model with Poisson family\nglm_poisson = sm.GLM(Y, X_scaled, family=sm.families.Poisson())\nglm_results = glm_poisson.fit()\n\n# Display the results: coefficients and standard errors\nglm_coefficients = glm_results.params\nglm_standard_errors = glm_results.bse\nglm_summary = glm_results.summary()\n\nglm_coefficients, glm_standard_errors, glm_summary\n\n(array([ 1.21543811,  1.04645998, -1.14084543,  0.11811441,  0.09859598,\n        -0.02009423,  0.05717196,  0.05134696]),\n array([0.0364255 , 0.10048749, 0.10249457, 0.03892044, 0.04200704,\n        0.05378329, 0.05267573, 0.04721241]),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                  Generalized Linear Model Regression Results                  \n ==============================================================================\n Dep. Variable:                      y   No. Observations:                 1500\n Model:                            GLM   Df Residuals:                     1492\n Model Family:                 Poisson   Df Model:                            7\n Link Function:                    Log   Scale:                          1.0000\n Method:                          IRLS   Log-Likelihood:                -3275.9\n Date:                Wed, 01 May 2024   Deviance:                       2178.8\n Time:                        06:35:59   Pearson chi2:                 2.11e+03\n No. Iterations:                     5   Pseudo R-squ. (CS):             0.1152\n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const          1.2154      0.036     33.368      0.000       1.144       1.287\n x1             1.0465      0.100     10.414      0.000       0.850       1.243\n x2            -1.1408      0.102    -11.131      0.000      -1.342      -0.940\n x3             0.1181      0.039      3.035      0.002       0.042       0.194\n x4             0.0986      0.042      2.347      0.019       0.016       0.181\n x5            -0.0201      0.054     -0.374      0.709      -0.126       0.085\n x6             0.0572      0.053      1.085      0.278      -0.046       0.160\n x7             0.0513      0.047      1.088      0.277      -0.041       0.144\n ==============================================================================\n \"\"\")\n\n\nThe GLM results from the statsmodels package provide coefficients and standard errors that align closely with the ones obtained from our custom optimization method. Here’s a summary of the findings:\nCoefficients and Standard Errors (Statsmodels GLM)\nHere is the table of coefficients and standard errors from a Generalized Linear Model (GLM) using the Statsmodels library:\n\n\n\nVariable\nCoefficient Estimate\nStandard Error\n\n\n\n\nIntercept\n1.215\n0.036\n\n\nAge (scaled)\n1.046\n0.100\n\n\nAge Squared (scaled)\n-1.141\n0.102\n\n\nCustomer Status\n0.118\n0.039\n\n\nRegion_Northeast\n0.098\n0.042\n\n\nRegion_South\n-0.020\n0.054\n\n\nRegion_Southwest\n0.057\n0.053\n\n\nRegion_Northwest\n0.051\n0.047\n\n\n\nThe coefficients estimated by the statsmodels GLM are quite similar to those from the scipy.optimize function, suggesting consistency across methods. Notably, the standard errors from the GLM are generally smaller, which might be due to differences in how the Hessian is calculated or the numerical stability offered by the statsmodels framework.\nThese results confirm the validity of our earlier optimization and highlight the potential influences of firm age, customer status, and regional location on the number of patents awarded. Such analyses can be crucial for Blueprinty to understand and possibly predict patent application success across different demographics and regions.\nThe results from the Poisson regression model provide insightful interpretations regarding the effect of various factors, including the use of Blueprinty’s software, on the number of patents awarded to engineering firms. Here are the key interpretations based on the coefficients obtained:\n\n\n\nIntercept (Base Effect):\n\nThe coefficient for the intercept is significantly positive, suggesting a base rate of patent awards when all other variables are zero.\n\nAge and Age Squared:\n\nThe positive coefficient for age indicates that, initially, as firms get older, they tend to receive more patents.\nThe negative coefficient for age squared suggests a diminishing return effect: as firms continue to age beyond a certain point, the increase in patents awarded slows down and eventually may decrease. This could reflect the lifecycle of firm innovation or shifts in focus as firms mature.\n\nCustomer Status (Use of Blueprinty’s Software):\n\nThe coefficient for customer status is positive and statistically significant (p-value &lt; 0.05), indicating that firms using Blueprinty’s software tend to have a higher number of patents awarded compared to those that do not use the software.\nThis result supports Blueprinty’s marketing claim that using their software is associated with higher patent success.\n\nRegional Variables:\n\nThe coefficients for regions (compared to a baseline region not included in the model to avoid dummy variable trap) show some variation in patent awards across different regions, with some coefficients being positive and others negative or statistically insignificant. This indicates regional differences in patent award rates, which could be influenced by local economic conditions, regional innovation trends, or the presence of research institutions.\n\n\nConclusions\n\nThe positive and significant effect of using Blueprinty’s software on the number of patents awarded supports the claim that the software potentially enhances patent application success. This effect remains even after controlling for firm age and regional differences.\nThe analysis also highlights the impact of firm age on patent success, with a peak effect after which the benefits decrease. This could inform Blueprinty’s targeting strategy, perhaps focusing more on firms at certain stages of their lifecycle.\nRegional variations suggest that market conditions or regional characteristics might also play a role in patent success, which could be important for regional marketing strategies.\n\nOverall, these results suggest that Blueprinty’s software is indeed associated with an increase in patent awards, providing empirical support for the marketing claims. This information could be very valuable for Blueprinty in demonstrating the effectiveness of their software to current and potential customers, and in refining their product development and marketing strategies based on the characteristics of the firms that benefit the most."
  },
  {
    "objectID": "projects/project1/hw2_questions.html#airbnb-case-study",
    "href": "projects/project1/hw2_questions.html#airbnb-case-study",
    "title": "Homework2 - Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\nFirst, we’ll read the data! The definitions for this dataset are already provided above.\n\nairbnb_data = pd.read_csv('/home/jovyan/code/MGTA 495/QUARTO_WEBSITE/data/airbnb.csv')\n\nairbnb_data.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\n\nStep 1: Exploratory Data Analysis (EDA)\n\nVisualization:\nThe first step of visualization represent the distribution of various numerical variables from an Airbnb dataset.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Setting the aesthetic style of the plots\nsns.set(style=\"whitegrid\")\n\n# Create a figure with subplots\nfig, axes = plt.subplots(3, 2, figsize=(14, 10))\n\n# Histograms for numerical variables\nsns.histplot(airbnb_data['number_of_reviews'], bins=30, ax=axes[0, 0], kde=True)\naxes[0, 0].set_title('Distribution of Number of Reviews')\n\nsns.histplot(airbnb_data['price'], bins=30, ax=axes[0, 1], kde=True)\naxes[0, 1].set_title('Distribution of Price')\n\nsns.histplot(airbnb_data['bedrooms'], bins=30, ax=axes[1, 0], kde=True)\naxes[1, 0].set_title('Distribution of Bedrooms')\n\nsns.histplot(airbnb_data['bathrooms'], bins=30, ax=axes[1, 1], kde=True)\naxes[1, 1].set_title('Distribution of Bathrooms')\n\nsns.histplot(airbnb_data['review_scores_cleanliness'], bins=10, ax=axes[2, 0], kde=True)\naxes[2, 0].set_title('Distribution of Cleanliness Scores')\n\nsns.histplot(airbnb_data['review_scores_value'], bins=10, ax=axes[2, 1], kde=True)\naxes[2, 1].set_title('Distribution of Value Scores')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nHere are the histograms for several key variables in the AirBnB dataset:\n\nNumber of Reviews: The distribution is right-skewed, indicating that most listings have a relatively small number of reviews, with a few listings having a very high number of reviews.\nPrice: This variable is also right-skewed, showing that most listings are priced at the lower end, with fewer listings at very high prices.\nBedrooms: Most listings have 1 or 2 bedrooms, with very few listings having more than that.\nBathrooms: The majority of listings have 1 bathroom, and the distribution is less varied than for bedrooms.\nCleanliness Scores: Scores are mostly high, clustering around 9 and 10, suggesting that most properties are well-rated for cleanliness.\nValue Scores: Like cleanliness, the value scores are also skewed towards the higher end.\n\n\n\nOutliers\nNext, we’ll look at box plots for these variables to identify outliers and then generate a correlation matrix to examine the relationships between them.\n\n# Create a figure with subplots for boxplots\nfig, axes = plt.subplots(3, 2, figsize=(8, 10))\n\n# Boxplots for numerical variables\nsns.boxplot(x=airbnb_data['number_of_reviews'], ax=axes[0, 0])\naxes[0, 0].set_title('Boxplot of Number of Reviews')\n\nsns.boxplot(x=airbnb_data['price'], ax=axes[0, 1])\naxes[0, 1].set_title('Boxplot of Price')\n\nsns.boxplot(x=airbnb_data['bedrooms'], ax=axes[1, 0])\naxes[1, 0].set_title('Boxplot of Bedrooms')\n\nsns.boxplot(x=airbnb_data['bathrooms'], ax=axes[1, 1])\naxes[1, 1].set_title('Boxplot of Bathrooms')\n\nsns.boxplot(x=airbnb_data['review_scores_cleanliness'], ax=axes[2, 0])\naxes[2, 0].set_title('Boxplot of Cleanliness Scores')\n\nsns.boxplot(x=airbnb_data['review_scores_value'], ax=axes[2, 1])\naxes[2, 1].set_title('Boxplot of Value Scores')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nBoxplots Analysis:\nThe boxplots reveal the following about the distribution of variables:\n\nNumber of Reviews: Many outliers exist above the upper whisker, indicating some listings have unusually high numbers of reviews.\nPrice: There are significant outliers with very high prices compared to the bulk of the data, indicating some luxury or overpriced listings.\nBedrooms and Bathrooms: Most listings have 1 or 2 bedrooms and usually 1 bathroom, but there are outliers showing listings with many bedrooms or bathrooms.\nCleanliness and Value Scores: Both scores show a few outliers on the lower side, indicating some listings are rated much lower than the average.\n\n\n# Correlation matrix plot\ncorr_matrix = airbnb_data[['number_of_reviews', 'price', 'bedrooms', 'bathrooms', 'review_scores_cleanliness', 'review_scores_value']].corr()\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\nplt.title('Correlation Matrix')\nplt.show()\n\n\n\n\n\n\n\n\nCorrelation Matrix:\nThe correlation matrix helps to visualize the relationships between variables:\n\nNumber of Reviews shows small to moderate positive correlations with bedrooms and bathrooms, suggesting that larger properties might receive more reviews.\nPrice is moderately positively correlated with the number of bedrooms and bathrooms, which is expected as larger properties generally cost more.\nReview Scores (Cleanliness and Value) do not show strong correlations with other numerical variables like price or number of reviews, indicating these scores might be influenced more by other factors not included in this subset of data.\n\n\n\n\nStep 2: Handling Missing Data\nBefore building the model, we have to make sure there are no missing values in our data.\n\n# Identifying and handling missing values\nmissing_data = airbnb_data.isnull().sum().sort_values(ascending=False)\npercent_missing = (airbnb_data.isnull().sum() / airbnb_data.isnull().count() * 100).sort_values(ascending=False)\n\nmissing_data_frame = pd.DataFrame({'Missing Values': missing_data, 'Percent Missing': percent_missing})\n\n# Display the dataframe containing missing data information\nmissing_data_frame[missing_data_frame['Missing Values'] &gt; 0]\n\n\n\n\n\n\n\n\nMissing Values\nPercent Missing\n\n\n\n\nreview_scores_value\n10256\n25.243674\n\n\nreview_scores_location\n10254\n25.238752\n\n\nreview_scores_cleanliness\n10195\n25.093532\n\n\nbathrooms\n160\n0.393817\n\n\nbedrooms\n76\n0.187063\n\n\nhost_since\n35\n0.086147\n\n\n\n\n\n\n\nThe missing data information shows:\n\nReview Scores (Value, Location, Cleanliness): Significant missing data (over 25%) which may require imputation or exclusion depending on the analysis.\nBathrooms and Bedrooms: Relatively small percentages of missing data, which might be handled by simple imputation techniques.\nHost Since: Very small percentage missing, potentially droppable or imputable.\n\nFor the next steps:\n\nReview Scores: Due to the high percentage of missing data, imputation may skew results. We may consider excluding these variables from the model or using a method like multiple imputation.\nBathrooms and Bedrooms: Given the low percentage, we could impute missing values using the median (to avoid the influence of outliers).\nHost Since: Since the missing percentage is minimal, rows with missing ‘host_since’ can be removed.\n\n\nfrom sklearn.impute import SimpleImputer\n\n# Create imputers for numerical data\nmedian_imputer = SimpleImputer(strategy='median')\nmode_imputer = SimpleImputer(strategy='most_frequent')\n\n# Imputing 'bathrooms' and 'bedrooms' with the median\nairbnb_data['bathrooms'] = median_imputer.fit_transform(airbnb_data[['bathrooms']])\nairbnb_data['bedrooms'] = median_imputer.fit_transform(airbnb_data[['bedrooms']])\n\n# Since 'host_since' has very few missing values, we will drop those rows\nairbnb_data = airbnb_data.dropna(subset=['host_since'])\n\n# For the review scores with significant missing values, consider excluding from the model \nairbnb_data_cleaned = airbnb_data.drop(columns=['review_scores_cleanliness', 'review_scores_location', 'review_scores_value'])\n\n# Check the dataframe after cleaning\nairbnb_data_cleaned.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 40593 entries, 0 to 40627\nData columns (total 11 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Unnamed: 0         40593 non-null  int64  \n 1   id                 40593 non-null  int64  \n 2   days               40593 non-null  int64  \n 3   last_scraped       40593 non-null  object \n 4   host_since         40593 non-null  object \n 5   room_type          40593 non-null  object \n 6   bathrooms          40593 non-null  float64\n 7   bedrooms           40593 non-null  float64\n 8   price              40593 non-null  int64  \n 9   number_of_reviews  40593 non-null  int64  \n 10  instant_bookable   40593 non-null  object \ndtypes: float64(2), int64(5), object(4)\nmemory usage: 3.7+ MB\n\n\nThe data has been cleaned and imputed where necessary:\n\nMissing values in bathrooms and bedrooms were filled with the median of their respective columns.\nRows with missing host_since data were removed, as they constituted a very small fraction of the dataset.\nColumns with a significant amount of missing data (review_scores_cleanliness, review_scores_location, review_scores_value) were removed from the dataset to simplify the analysis.\n\nNow, dataset contains 40,593 entries with no missing values in the remaining columns.\n\n\nStep 3: Model Building\n\nPoisson regression model\nThe dataset is now prepared for modeling. Here’s a breakdown of the steps we completed:\n\nCategorical Encoding: The categorical variables room_type and instant_bookable were encoded into numeric formats using one-hot encoding. The first category of each variable was dropped to avoid multicollinearity.\nFeature Selection: We included relevant features for the model, such as days listed (days), number of bathrooms and bedrooms, and price.\nDropping Non-Relevant Columns: We removed columns like ‘Unnamed: 0’, ‘last_scraped’, ‘host_since’, and ‘id’ as they are identifiers or provide temporal information not useful for modeling.\n\n\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Prepare the dataset for modeling\n\n# 1. Convert categorical variables using OneHotEncoder\nencoder = OneHotEncoder(drop='first', sparse=False)  # Drop first to avoid multicollinearity\ncategorical_data = encoder.fit_transform(airbnb_data_cleaned[['room_type', 'instant_bookable']])\n\n# Creating a DataFrame from the encoded categorical data\ncategorical_cols = encoder.get_feature_names_out(['room_type', 'instant_bookable'])\ncategorical_df = pd.DataFrame(categorical_data, columns=categorical_cols, index=airbnb_data_cleaned.index)\n\n# 2. Combine the new categorical dataframe with the original dataframe (excluding the original categorical columns)\nairbnb_model_data = pd.concat([airbnb_data_cleaned.drop(['room_type', 'instant_bookable'], axis=1), categorical_df], axis=1)\n\n# 3. Drop any non-relevant columns (e.g., 'Unnamed: 0', 'last_scraped', 'host_since', 'id' as they are identifiers or temporal data not useful for modeling)\nairbnb_model_data = airbnb_model_data.drop(['Unnamed: 0', 'last_scraped', 'host_since', 'id'], axis=1)\n\n# Display the prepared model data\nairbnb_model_data.head()\n\n/opt/conda/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning:\n\n`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n\n\n\n\n\n\n\n\n\n\ndays\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nroom_type_Private room\nroom_type_Shared room\ninstant_bookable_t\n\n\n\n\n0\n3130\n1.0\n1.0\n59\n150\n1.0\n0.0\n0.0\n\n\n1\n3127\n1.0\n0.0\n230\n20\n0.0\n0.0\n0.0\n\n\n2\n3050\n1.0\n1.0\n150\n0\n1.0\n0.0\n0.0\n\n\n3\n3038\n1.0\n1.0\n89\n116\n0.0\n0.0\n0.0\n\n\n4\n3012\n1.0\n1.0\n39\n93\n1.0\n0.0\n1.0\n\n\n\n\n\n\n\nFeatures Included for Modeling:\n\ndays: Number of days the unit has been listed on Airbnb.\nbathrooms: Number of bathrooms.\nbedrooms: Number of bedrooms.\nprice: Price per night in dollars.\nnumber_of_reviews: As a proxy for the number of bookings.\nroom_type_Private room and room_type_Shared room: Indicators for the type of room\ninstant_bookable_t: Indicator for whether the listing is instantly bookable, with the baseline being not instantly bookable.\n\nNext, we’ll build the Poisson regression model with number_of_reviews as the dependent variable, given that it’s a count data proxy for bookings.\n\nimport statsmodels.api as sm\n\n# Setting up the Poisson regression model\nX = airbnb_model_data.drop('number_of_reviews', axis=1)  # Independent variables\ny = airbnb_model_data['number_of_reviews']  # Dependent variable (count of reviews)\n\n# Adding a constant to the model (intercept)\nX = sm.add_constant(X)\n\n# Building the Poisson regression model\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson()).fit()\n\n# Display the model summary\npoisson_model.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nnumber_of_reviews\nNo. Observations:\n40593\n\n\nModel:\nGLM\nDf Residuals:\n40585\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-6.6234e+05\n\n\nDate:\nWed, 01 May 2024\nDeviance:\n1.2007e+06\n\n\nTime:\n06:36:02\nPearson chi2:\n1.76e+06\n\n\nNo. Iterations:\n6\nPseudo R-squ. (CS):\n0.9673\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.0112\n0.005\n389.655\n0.000\n2.001\n2.021\n\n\ndays\n0.0006\n1.83e-06\n347.040\n0.000\n0.001\n0.001\n\n\nbathrooms\n-0.1017\n0.004\n-26.348\n0.000\n-0.109\n-0.094\n\n\nbedrooms\n0.0966\n0.002\n47.085\n0.000\n0.093\n0.101\n\n\nprice\n-0.0005\n1.24e-05\n-38.120\n0.000\n-0.000\n-0.000\n\n\nroom_type_Private room\n-0.0935\n0.003\n-32.901\n0.000\n-0.099\n-0.088\n\n\nroom_type_Shared room\n-0.2240\n0.009\n-25.890\n0.000\n-0.241\n-0.207\n\n\ninstant_bookable_t\n0.5153\n0.003\n177.863\n0.000\n0.510\n0.521\n\n\n\n\n\nThe Poisson regression model has been successfully estimated, and here’s a summary of the findings:\n\n\nModel Coefficients Interpretation:\n\nConstant (Intercept): The base log-count of reviews when all other variables are zero is approximately 2.0112.\nDays (0.0006): For each additional day a listing is on Airbnb, there is a small positive effect on the log-count of reviews, suggesting longer-listed properties tend to accumulate more reviews.\nBathrooms (-0.1017): Having more bathrooms is associated with a slight decrease in the number of reviews, which might indicate that properties with more bathrooms are not booked as frequently, possibly due to higher costs.\nBedrooms (0.0966): More bedrooms positively influence the number of reviews, consistent with the idea that larger properties can accommodate more guests and thus receive more reviews.\nPrice (-0.0005): Higher prices are associated with fewer reviews, indicating that more expensive listings might be booked less frequently.\nRoom Type (Private and Shared): Listings that are private rooms have fewer reviews compared to entire homes/apartments, and shared rooms have even fewer reviews than private rooms.\nInstant Bookable (0.5153): Listings that are instantly bookable receive significantly more reviews, suggesting that convenience boosts bookings.\n\n\n\nModel Fit and Diagnostics:\n\nThe model uses the log link function, suitable for count data in a Poisson model.\nPseudo R-squared (Comparative Fit Index): 0.9673 suggests a good fit of the model to the data.\nDeviance and Pearson chi2: These statistics indicate the model’s goodness of fit, showing the deviation of the observed from the expected frequencies.\n\n\n\n\nStep 4: Model Estimation\n\nCheck for Overdispersion\nThe ratio of the Pearson chi2 statistic to the degrees of freedom should be checked to see if a Negative Binomial model is more appropriate due to overdispersion.\n\n# Calculating overdispersion\nchi_squared = poisson_model.pearson_chi2\ndegrees_of_freedom = poisson_model.df_resid\n\n# Overdispersion factor\noverdispersion_factor = chi_squared / degrees_of_freedom\n\nprint('Overdispersion_factor of Poisson regression model is ',overdispersion_factor)\n\nOverdispersion_factor of Poisson regression model is  43.47338957827485\n\n\nThe calculated overdispersion factor for our Poisson regression model is approximately 43.47. This value is substantially greater than 1, indicating significant overdispersion in the data.\nImplications:\nOverdispersion occurs when the variance of the count data is greater than the mean (a key assumption of the Poisson distribution). This discrepancy can lead to underestimated standard errors and subsequently, to inflated test statistics and narrower confidence intervals, potentially leading to erroneous conclusions.\nGiven the presence of overdispersion, it may be more appropriate to use a Negative Binomial regression model, which can handle variability exceeding that assumed under the Poisson distribution.\n\n\nNegative Binomial model\n\nfrom statsmodels.discrete.discrete_model import NegativeBinomial\nfrom sklearn.preprocessing import StandardScaler\n\n# Instantiate the scaler\nscaler = StandardScaler()\n\n# Select numeric columns for scaling (excluding the dependent variable and one-hot encoded variables)\nnumeric_columns = ['days', 'bathrooms', 'bedrooms', 'price']\nscaled_data = scaler.fit_transform(airbnb_model_data[numeric_columns])\n\n# Create a DataFrame from the scaled data\nscaled_df = pd.DataFrame(scaled_data, columns=numeric_columns, index=airbnb_model_data.index)\n\n# Combine scaled data with the rest of the model data (excluding the original unscaled columns)\nairbnb_scaled_model_data = pd.concat([airbnb_model_data.drop(numeric_columns, axis=1), scaled_df], axis=1)\n\n# Re-prepare the X and y for the model\nX_scaled = airbnb_scaled_model_data.drop('number_of_reviews', axis=1)\ny_scaled = airbnb_scaled_model_data['number_of_reviews']\n\n# Add a constant to the model (intercept)\nX_scaled = sm.add_constant(X_scaled)\n\n# Try fitting the Negative Binomial model again with scaled data\nnb_model_scaled = NegativeBinomial(y_scaled, X_scaled).fit()\n\n# Display the model summary\nnb_model_scaled.summary()\n\nOptimization terminated successfully.\n         Current function value: 3.437230\n         Iterations: 28\n         Function evaluations: 29\n         Gradient evaluations: 29\n\n\n\nNegativeBinomial Regression Results\n\n\nDep. Variable:\nnumber_of_reviews\nNo. Observations:\n40593\n\n\nModel:\nNegativeBinomial\nDf Residuals:\n40585\n\n\nMethod:\nMLE\nDf Model:\n7\n\n\nDate:\nWed, 01 May 2024\nPseudo R-squ.:\n0.01133\n\n\nTime:\n06:36:02\nLog-Likelihood:\n-1.3953e+05\n\n\nconverged:\nTrue\nLL-Null:\n-1.4113e+05\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.000\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.6279\n0.012\n213.190\n0.000\n2.604\n2.652\n\n\nroom_type_Private room\n-0.1245\n0.017\n-7.265\n0.000\n-0.158\n-0.091\n\n\nroom_type_Shared room\n-0.2346\n0.049\n-4.813\n0.000\n-0.330\n-0.139\n\n\ninstant_bookable_t\n0.4977\n0.021\n23.979\n0.000\n0.457\n0.538\n\n\ndays\n0.4489\n0.009\n51.265\n0.000\n0.432\n0.466\n\n\nbathrooms\n-0.0289\n0.009\n-3.372\n0.001\n-0.046\n-0.012\n\n\nbedrooms\n0.0653\n0.009\n7.203\n0.000\n0.048\n0.083\n\n\nprice\n-0.0560\n0.006\n-8.843\n0.000\n-0.068\n-0.044\n\n\nalpha\n2.6011\n0.019\n139.327\n0.000\n2.565\n2.638\n\n\n\n\n\nThe Negative Binomial regression model with scaled data has successfully converged, and here are the results:\n\n\nModel Coefficients Interpretation:\n\nConstant (Intercept): The base log-count of reviews when all predictors are at their mean values is approximately 2.6279.\nDays (0.4489): The scaled coefficient suggests a strong positive impact of the number of days listed on the number of reviews, indicating that older listings tend to have more reviews.\nBathrooms (-0.0289): More bathrooms in a listing slightly decrease the expected count of reviews, potentially due to higher costs or specific types of properties.\nBedrooms (0.0653): More bedrooms slightly increase the number of reviews, consistent with the capacity to host more guests.\nPrice (-0.0560): Higher prices reduce the expected count of reviews, implying that more expensive listings may be booked less frequently.\nRoom Type (Private and Shared): Both private and shared rooms receive fewer reviews compared to entire homes/apartments, with shared rooms experiencing a larger decrease.\nInstant Bookable (0.4977): Listings that are instantly bookable have significantly more reviews, reinforcing the value of convenience.\nAlpha (2.6011): The dispersion parameter remains high, indicating appropriate use of the Negative Binomial model due to overdispersion in the data.\n\n\n\nDiagnostic Checks:\nFurther diagnostic checks should be performed to ensure the model fits well and the assumptions hold.\n\n# Model Diagnostics for the Negative Binomial Regression Model\nfrom statsmodels.graphics.gofplots import qqplot\n\n# Plotting the residuals\nresiduals = nb_model_scaled.resid_response\n\n# Creating diagnostic plots\nfig, ax = plt.subplots(1, 2, figsize=(6, 8))\n\n# Q-Q plot for residuals to check normality\nqqplot(residuals, line='45', ax=ax[0])\nax[0].set_title('Q-Q Plot of Residuals')\n\n# Residuals plot to check homoscedasticity and outliers\nsns.histplot(residuals, bins=50, kde=True, ax=ax[1])\nax[1].set_title('Histogram of Residuals')\n\nplt.show()\n\n# Checking for patterns in residuals\nplt.figure(figsize=(8, 6))\nplt.scatter(y_scaled, residuals)\nplt.title('Residuals vs Fitted Values')\nplt.xlabel('Fitted Values')\nplt.ylabel('Residuals')\nplt.axhline(y=0, color='red', linestyle='--')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiagnostic Checks Analysis:\nHere’s an overview of the diagnostic checks for the Negative Binomial regression model:\n\nQ-Q Plot of Residuals:\n\n\nThis plot helps assess the normality of residuals. Ideally, the residuals should lie along the 45-degree line if they are normally distributed. Deviations from this line suggest departures from normality, which could indicate issues with model fit or assumptions.\n\n\nHistogram of Residuals:\n\n\nThe histogram provides a visual representation of the distribution of residuals. It appears the residuals are not perfectly normally distributed, showing some skewness. This is not unusual for count data models, but it does suggest checking whether the model assumptions are adequately met.\n\n\nResiduals vs. Fitted Values:\n\n\nIdeally, there should be no clear pattern or systematic structure in this plot. The presence of patterns or trends could indicate issues with model fit, such as non-linearity or omitted variables. The plot here does not show a clear pattern, which generally suggests that the model does not suffer from obvious issues like heteroscedasticity or non-linear relationships that have not been accounted for.\n\nConclusion:\nThe diagnostics suggest that while the residuals do not follow a perfect normal distribution (which is common in count data models), there aren’t clear signs of heteroscedasticity or problematic patterns between the residuals and fitted values. However, the slight deviation in the Q-Q plot and the distribution of residuals could indicate that further model adjustments or transformations might be beneficial, especially to better handle any underlying skewness or overdispersion not fully accounted for.\n\n\n\nStep 5: Compared with two different models\n\n# Extracting AIC values for comparison\npoisson_aic = poisson_model.aic\nnb_aic = nb_model_scaled.aic\n\nprint('AIC of Poisson Model is',poisson_aic) \nprint('AIC of Negative Binomial Model is',nb_aic)\n\nAIC of Poisson Model is 1324704.7950103276\nAIC of Negative Binomial Model is 279072.9591164948\n\n\n\nModel Coefficients:\nBoth models show similar directions in the influence of predictors:\nDays, bedrooms, and instant bookable status positively affect the number of reviews. Price and higher bathrooms negatively affect reviews, more so in the Poisson model.\nRoom type variations show that private and shared rooms generally receive fewer reviews compared to entire homes/apartments.\n\n\nGoodness-of-Fit Indicators:\nPoisson Model: Generally showed signs of underfitting due to overdispersion, indicated by high deviance.\nNegative Binomial Model: Improved fit, accommodating overdispersion with the inclusion of the dispersion parameter (alpha).\n\n\nPredictive Performance:\nA formal comparison using cross-validation or split-sample testing would be ideal to assess this aspect, but from the fitting process:\nNegative Binomial Model: Likely provides more reliable predictions due to better handling of data variability.\n\n\nAIC Values:\nThe Negative Binomial model show a lower AIC when fitting count data with overdispersion, indicating a better balance of model fit and complexity.\n\n\nConclusion:\nPoisson regression model:\nThe Poisson regression model reveals several important factors influencing the number of reviews an Airbnb listing receives. The duration a listing has been posted and whether it is instantly bookable significantly increase reviews, reflecting longer exposure and user convenience. In contrast, higher prices and more bathrooms decrease the number of reviews, which may be related to the target market and affordability.\nNegative Binomial model:\nThe Negative Binomial model provides a robust framework for understanding factors that influence the number of reviews an Airbnb listing receives. It accounts for overdispersion in the data, making it a more reliable choice than the Poisson model for this dataset. The results indicate that practical features such as duration of listing, type of room, and instant bookability significantly affect guest interaction in terms of reviews. Listings that are more affordable, offer convenience, and cater to larger groups tend to receive more reviews.\n\n\nImplications:\nPoisson regression model\nThese findings can inform Airbnb hosts about optimizing their listings for more reviews and potentially more bookings. For instance, setting competitive prices and offering instant booking options could enhance a listing’s attractiveness and activity. Hosts with properties having multiple bathrooms may need to consider their pricing strategy or marketing approach, particularly if targeting larger groups or longer stays.\nNegative Binomial model\nThis model can guide Airbnb hosts in optimizing their properties to attract more reviews, which can enhance visibility and booking probabilities on the platform. Showing similar implications with the Poisson regression model."
  },
  {
    "objectID": "projects/project1/hw2_questions.html#step-1-exploratory-data-analysis-eda",
    "href": "projects/project1/hw2_questions.html#step-1-exploratory-data-analysis-eda",
    "title": "Homework2 - Poisson Regression Examples",
    "section": "Step 1: Exploratory Data Analysis (EDA)",
    "text": "Step 1: Exploratory Data Analysis (EDA)\n\nVisualization:\nThe first step of visualization represent the distribution of various numerical variables from an Airbnb dataset.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Setting the aesthetic style of the plots\nsns.set(style=\"whitegrid\")\n\n# Create a figure with subplots\nfig, axes = plt.subplots(3, 2, figsize=(14, 10))\n\n# Histograms for numerical variables\nsns.histplot(airbnb_data['number_of_reviews'], bins=30, ax=axes[0, 0], kde=True)\naxes[0, 0].set_title('Distribution of Number of Reviews')\n\nsns.histplot(airbnb_data['price'], bins=30, ax=axes[0, 1], kde=True)\naxes[0, 1].set_title('Distribution of Price')\n\nsns.histplot(airbnb_data['bedrooms'], bins=30, ax=axes[1, 0], kde=True)\naxes[1, 0].set_title('Distribution of Bedrooms')\n\nsns.histplot(airbnb_data['bathrooms'], bins=30, ax=axes[1, 1], kde=True)\naxes[1, 1].set_title('Distribution of Bathrooms')\n\nsns.histplot(airbnb_data['review_scores_cleanliness'], bins=10, ax=axes[2, 0], kde=True)\naxes[2, 0].set_title('Distribution of Cleanliness Scores')\n\nsns.histplot(airbnb_data['review_scores_value'], bins=10, ax=axes[2, 1], kde=True)\naxes[2, 1].set_title('Distribution of Value Scores')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nHere are the histograms for several key variables in the AirBnB dataset:\n\nNumber of Reviews: The distribution is right-skewed, indicating that most listings have a relatively small number of reviews, with a few listings having a very high number of reviews.\nPrice: This variable is also right-skewed, showing that most listings are priced at the lower end, with fewer listings at very high prices.\nBedrooms: Most listings have 1 or 2 bedrooms, with very few listings having more than that.\nBathrooms: The majority of listings have 1 bathroom, and the distribution is less varied than for bedrooms.\nCleanliness Scores: Scores are mostly high, clustering around 9 and 10, suggesting that most properties are well-rated for cleanliness.\nValue Scores: Like cleanliness, the value scores are also skewed towards the higher end.\n\n\n\nOutliers\nNext, we’ll look at box plots for these variables to identify outliers and then generate a correlation matrix to examine the relationships between them.\n\n# Create a figure with subplots for boxplots\nfig, axes = plt.subplots(3, 2, figsize=(8, 10))\n\n# Boxplots for numerical variables\nsns.boxplot(x=airbnb_data['number_of_reviews'], ax=axes[0, 0])\naxes[0, 0].set_title('Boxplot of Number of Reviews')\n\nsns.boxplot(x=airbnb_data['price'], ax=axes[0, 1])\naxes[0, 1].set_title('Boxplot of Price')\n\nsns.boxplot(x=airbnb_data['bedrooms'], ax=axes[1, 0])\naxes[1, 0].set_title('Boxplot of Bedrooms')\n\nsns.boxplot(x=airbnb_data['bathrooms'], ax=axes[1, 1])\naxes[1, 1].set_title('Boxplot of Bathrooms')\n\nsns.boxplot(x=airbnb_data['review_scores_cleanliness'], ax=axes[2, 0])\naxes[2, 0].set_title('Boxplot of Cleanliness Scores')\n\nsns.boxplot(x=airbnb_data['review_scores_value'], ax=axes[2, 1])\naxes[2, 1].set_title('Boxplot of Value Scores')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nBoxplots Analysis:\nThe boxplots reveal the following about the distribution of variables:\n\nNumber of Reviews: Many outliers exist above the upper whisker, indicating some listings have unusually high numbers of reviews.\nPrice: There are significant outliers with very high prices compared to the bulk of the data, indicating some luxury or overpriced listings.\nBedrooms and Bathrooms: Most listings have 1 or 2 bedrooms and usually 1 bathroom, but there are outliers showing listings with many bedrooms or bathrooms.\nCleanliness and Value Scores: Both scores show a few outliers on the lower side, indicating some listings are rated much lower than the average.\n\n\n# Correlation matrix plot\ncorr_matrix = airbnb_data[['number_of_reviews', 'price', 'bedrooms', 'bathrooms', 'review_scores_cleanliness', 'review_scores_value']].corr()\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\nplt.title('Correlation Matrix')\nplt.show()\n\n\n\n\n\n\n\n\nCorrelation Matrix:\nThe correlation matrix helps to visualize the relationships between variables:\n\nNumber of Reviews shows small to moderate positive correlations with bedrooms and bathrooms, suggesting that larger properties might receive more reviews.\nPrice is moderately positively correlated with the number of bedrooms and bathrooms, which is expected as larger properties generally cost more.\nReview Scores (Cleanliness and Value) do not show strong correlations with other numerical variables like price or number of reviews, indicating these scores might be influenced more by other factors not included in this subset of data."
  },
  {
    "objectID": "projects/project1/hw2_questions.html#step-2-handling-missing-data",
    "href": "projects/project1/hw2_questions.html#step-2-handling-missing-data",
    "title": "Homework2 - Poisson Regression Examples",
    "section": "Step 2: Handling Missing Data",
    "text": "Step 2: Handling Missing Data\nBefore building the model, we have to make sure there are no missing values in our data.\n\n# Identifying and handling missing values\nmissing_data = airbnb_data.isnull().sum().sort_values(ascending=False)\npercent_missing = (airbnb_data.isnull().sum() / airbnb_data.isnull().count() * 100).sort_values(ascending=False)\n\nmissing_data_frame = pd.DataFrame({'Missing Values': missing_data, 'Percent Missing': percent_missing})\n\n# Display the dataframe containing missing data information\nmissing_data_frame[missing_data_frame['Missing Values'] &gt; 0]\n\n\n\n\n\n\n\n\nMissing Values\nPercent Missing\n\n\n\n\nreview_scores_value\n10256\n25.243674\n\n\nreview_scores_location\n10254\n25.238752\n\n\nreview_scores_cleanliness\n10195\n25.093532\n\n\nbathrooms\n160\n0.393817\n\n\nbedrooms\n76\n0.187063\n\n\nhost_since\n35\n0.086147\n\n\n\n\n\n\n\nThe missing data information shows:\n\nReview Scores (Value, Location, Cleanliness): Significant missing data (over 25%) which may require imputation or exclusion depending on the analysis.\nBathrooms and Bedrooms: Relatively small percentages of missing data, which might be handled by simple imputation techniques.\nHost Since: Very small percentage missing, potentially droppable or imputable.\n\nFor the next steps:\n\nReview Scores: Due to the high percentage of missing data, imputation may skew results. We may consider excluding these variables from the model or using a method like multiple imputation.\nBathrooms and Bedrooms: Given the low percentage, we could impute missing values using the median (to avoid the influence of outliers).\nHost Since: Since the missing percentage is minimal, rows with missing ‘host_since’ can be removed.\n\n\nfrom sklearn.impute import SimpleImputer\n\n# Create imputers for numerical data\nmedian_imputer = SimpleImputer(strategy='median')\nmode_imputer = SimpleImputer(strategy='most_frequent')\n\n# Imputing 'bathrooms' and 'bedrooms' with the median\nairbnb_data['bathrooms'] = median_imputer.fit_transform(airbnb_data[['bathrooms']])\nairbnb_data['bedrooms'] = median_imputer.fit_transform(airbnb_data[['bedrooms']])\n\n# Since 'host_since' has very few missing values, we will drop those rows\nairbnb_data = airbnb_data.dropna(subset=['host_since'])\n\n# For the review scores with significant missing values, consider excluding from the model \nairbnb_data_cleaned = airbnb_data.drop(columns=['review_scores_cleanliness', 'review_scores_location', 'review_scores_value'])\n\n# Check the dataframe after cleaning\nairbnb_data_cleaned.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 40593 entries, 0 to 40627\nData columns (total 11 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Unnamed: 0         40593 non-null  int64  \n 1   id                 40593 non-null  int64  \n 2   days               40593 non-null  int64  \n 3   last_scraped       40593 non-null  object \n 4   host_since         40593 non-null  object \n 5   room_type          40593 non-null  object \n 6   bathrooms          40593 non-null  float64\n 7   bedrooms           40593 non-null  float64\n 8   price              40593 non-null  int64  \n 9   number_of_reviews  40593 non-null  int64  \n 10  instant_bookable   40593 non-null  object \ndtypes: float64(2), int64(5), object(4)\nmemory usage: 3.7+ MB\n\n\nThe data has been cleaned and imputed where necessary:\n\nMissing values in bathrooms and bedrooms were filled with the median of their respective columns.\nRows with missing host_since data were removed, as they constituted a very small fraction of the dataset.\nColumns with a significant amount of missing data (review_scores_cleanliness, review_scores_location, review_scores_value) were removed from the dataset to simplify the analysis.\n\nNow, dataset contains 40,593 entries with no missing values in the remaining columns."
  },
  {
    "objectID": "projects/project1/hw2_questions.html#step-3-model-building",
    "href": "projects/project1/hw2_questions.html#step-3-model-building",
    "title": "Homework2 - Poisson Regression Examples",
    "section": "Step 3: Model Building",
    "text": "Step 3: Model Building\n\nPoisson regression model\nThe dataset is now prepared for modeling. Here’s a breakdown of the steps we completed:\n\nCategorical Encoding: The categorical variables room_type and instant_bookable were encoded into numeric formats using one-hot encoding. The first category of each variable was dropped to avoid multicollinearity.\nFeature Selection: We included relevant features for the model, such as days listed (days), number of bathrooms and bedrooms, and price.\nDropping Non-Relevant Columns: We removed columns like ‘Unnamed: 0’, ‘last_scraped’, ‘host_since’, and ‘id’ as they are identifiers or provide temporal information not useful for modeling.\n\n\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Prepare the dataset for modeling\n\n# 1. Convert categorical variables using OneHotEncoder\nencoder = OneHotEncoder(drop='first', sparse=False)  # Drop first to avoid multicollinearity\ncategorical_data = encoder.fit_transform(airbnb_data_cleaned[['room_type', 'instant_bookable']])\n\n# Creating a DataFrame from the encoded categorical data\ncategorical_cols = encoder.get_feature_names_out(['room_type', 'instant_bookable'])\ncategorical_df = pd.DataFrame(categorical_data, columns=categorical_cols, index=airbnb_data_cleaned.index)\n\n# 2. Combine the new categorical dataframe with the original dataframe (excluding the original categorical columns)\nairbnb_model_data = pd.concat([airbnb_data_cleaned.drop(['room_type', 'instant_bookable'], axis=1), categorical_df], axis=1)\n\n# 3. Drop any non-relevant columns (e.g., 'Unnamed: 0', 'last_scraped', 'host_since', 'id' as they are identifiers or temporal data not useful for modeling)\nairbnb_model_data = airbnb_model_data.drop(['Unnamed: 0', 'last_scraped', 'host_since', 'id'], axis=1)\n\n# Display the prepared model data\nairbnb_model_data.head()\n\n/opt/conda/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning:\n\n`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n\n\n\n\n\n\n\n\n\n\ndays\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nroom_type_Private room\nroom_type_Shared room\ninstant_bookable_t\n\n\n\n\n0\n3130\n1.0\n1.0\n59\n150\n1.0\n0.0\n0.0\n\n\n1\n3127\n1.0\n0.0\n230\n20\n0.0\n0.0\n0.0\n\n\n2\n3050\n1.0\n1.0\n150\n0\n1.0\n0.0\n0.0\n\n\n3\n3038\n1.0\n1.0\n89\n116\n0.0\n0.0\n0.0\n\n\n4\n3012\n1.0\n1.0\n39\n93\n1.0\n0.0\n1.0\n\n\n\n\n\n\n\nFeatures Included for Modeling:\n\ndays: Number of days the unit has been listed on Airbnb.\nbathrooms: Number of bathrooms.\nbedrooms: Number of bedrooms.\nprice: Price per night in dollars.\nnumber_of_reviews: As a proxy for the number of bookings.\nroom_type_Private room and room_type_Shared room: Indicators for the type of room\ninstant_bookable_t: Indicator for whether the listing is instantly bookable, with the baseline being not instantly bookable.\n\nNext, we’ll build the Poisson regression model with number_of_reviews as the dependent variable, given that it’s a count data proxy for bookings.\n\nimport statsmodels.api as sm\n\n# Setting up the Poisson regression model\nX = airbnb_model_data.drop('number_of_reviews', axis=1)  # Independent variables\ny = airbnb_model_data['number_of_reviews']  # Dependent variable (count of reviews)\n\n# Adding a constant to the model (intercept)\nX = sm.add_constant(X)\n\n# Building the Poisson regression model\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson()).fit()\n\n# Display the model summary\npoisson_model.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nnumber_of_reviews\nNo. Observations:\n40593\n\n\nModel:\nGLM\nDf Residuals:\n40585\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-6.6234e+05\n\n\nDate:\nWed, 01 May 2024\nDeviance:\n1.2007e+06\n\n\nTime:\n06:32:22\nPearson chi2:\n1.76e+06\n\n\nNo. Iterations:\n6\nPseudo R-squ. (CS):\n0.9673\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.0112\n0.005\n389.655\n0.000\n2.001\n2.021\n\n\ndays\n0.0006\n1.83e-06\n347.040\n0.000\n0.001\n0.001\n\n\nbathrooms\n-0.1017\n0.004\n-26.348\n0.000\n-0.109\n-0.094\n\n\nbedrooms\n0.0966\n0.002\n47.085\n0.000\n0.093\n0.101\n\n\nprice\n-0.0005\n1.24e-05\n-38.120\n0.000\n-0.000\n-0.000\n\n\nroom_type_Private room\n-0.0935\n0.003\n-32.901\n0.000\n-0.099\n-0.088\n\n\nroom_type_Shared room\n-0.2240\n0.009\n-25.890\n0.000\n-0.241\n-0.207\n\n\ninstant_bookable_t\n0.5153\n0.003\n177.863\n0.000\n0.510\n0.521\n\n\n\n\n\nThe Poisson regression model has been successfully estimated, and here’s a summary of the findings:\n\nModel Coefficients Interpretation:\n\nConstant (Intercept): The base log-count of reviews when all other variables are zero is approximately 2.0112.\nDays (0.0006): For each additional day a listing is on Airbnb, there is a small positive effect on the log-count of reviews, suggesting longer-listed properties tend to accumulate more reviews.\nBathrooms (-0.1017): Having more bathrooms is associated with a slight decrease in the number of reviews, which might indicate that properties with more bathrooms are not booked as frequently, possibly due to higher costs.\nBedrooms (0.0966): More bedrooms positively influence the number of reviews, consistent with the idea that larger properties can accommodate more guests and thus receive more reviews.\nPrice (-0.0005): Higher prices are associated with fewer reviews, indicating that more expensive listings might be booked less frequently.\nRoom Type (Private and Shared): Listings that are private rooms have fewer reviews compared to entire homes/apartments, and shared rooms have even fewer reviews than private rooms.\nInstant Bookable (0.5153): Listings that are instantly bookable receive significantly more reviews, suggesting that convenience boosts bookings.\n\n\n\nModel Fit and Diagnostics:\n\nThe model uses the log link function, suitable for count data in a Poisson model.\nPseudo R-squared (Comparative Fit Index): 0.9673 suggests a good fit of the model to the data.\nDeviance and Pearson chi2: These statistics indicate the model’s goodness of fit, showing the deviation of the observed from the expected frequencies."
  },
  {
    "objectID": "projects/project1/hw2_questions.html#step-4-model-estimation",
    "href": "projects/project1/hw2_questions.html#step-4-model-estimation",
    "title": "Homework2 - Poisson Regression Examples",
    "section": "Step 4: Model Estimation",
    "text": "Step 4: Model Estimation\n\nCheck for Overdispersion\nThe ratio of the Pearson chi2 statistic to the degrees of freedom should be checked to see if a Negative Binomial model is more appropriate due to overdispersion.\n\n# Calculating overdispersion\nchi_squared = poisson_model.pearson_chi2\ndegrees_of_freedom = poisson_model.df_resid\n\n# Overdispersion factor\noverdispersion_factor = chi_squared / degrees_of_freedom\n\nprint('Overdispersion_factor of Poisson regression model is ',overdispersion_factor)\n\nOverdispersion_factor of Poisson regression model is  43.47338957827485\n\n\nThe calculated overdispersion factor for our Poisson regression model is approximately 43.47. This value is substantially greater than 1, indicating significant overdispersion in the data.\nImplications:\nOverdispersion occurs when the variance of the count data is greater than the mean (a key assumption of the Poisson distribution). This discrepancy can lead to underestimated standard errors and subsequently, to inflated test statistics and narrower confidence intervals, potentially leading to erroneous conclusions.\nGiven the presence of overdispersion, it may be more appropriate to use a Negative Binomial regression model, which can handle variability exceeding that assumed under the Poisson distribution.\n\n\nNegative Binomial model\n\nfrom statsmodels.discrete.discrete_model import NegativeBinomial\nfrom sklearn.preprocessing import StandardScaler\n\n# Instantiate the scaler\nscaler = StandardScaler()\n\n# Select numeric columns for scaling (excluding the dependent variable and one-hot encoded variables)\nnumeric_columns = ['days', 'bathrooms', 'bedrooms', 'price']\nscaled_data = scaler.fit_transform(airbnb_model_data[numeric_columns])\n\n# Create a DataFrame from the scaled data\nscaled_df = pd.DataFrame(scaled_data, columns=numeric_columns, index=airbnb_model_data.index)\n\n# Combine scaled data with the rest of the model data (excluding the original unscaled columns)\nairbnb_scaled_model_data = pd.concat([airbnb_model_data.drop(numeric_columns, axis=1), scaled_df], axis=1)\n\n# Re-prepare the X and y for the model\nX_scaled = airbnb_scaled_model_data.drop('number_of_reviews', axis=1)\ny_scaled = airbnb_scaled_model_data['number_of_reviews']\n\n# Add a constant to the model (intercept)\nX_scaled = sm.add_constant(X_scaled)\n\n# Try fitting the Negative Binomial model again with scaled data\nnb_model_scaled = NegativeBinomial(y_scaled, X_scaled).fit()\n\n# Display the model summary\nnb_model_scaled.summary()\n\nOptimization terminated successfully.\n         Current function value: 3.437230\n         Iterations: 28\n         Function evaluations: 29\n         Gradient evaluations: 29\n\n\n\nNegativeBinomial Regression Results\n\n\nDep. Variable:\nnumber_of_reviews\nNo. Observations:\n40593\n\n\nModel:\nNegativeBinomial\nDf Residuals:\n40585\n\n\nMethod:\nMLE\nDf Model:\n7\n\n\nDate:\nWed, 01 May 2024\nPseudo R-squ.:\n0.01133\n\n\nTime:\n06:32:23\nLog-Likelihood:\n-1.3953e+05\n\n\nconverged:\nTrue\nLL-Null:\n-1.4113e+05\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.000\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.6279\n0.012\n213.190\n0.000\n2.604\n2.652\n\n\nroom_type_Private room\n-0.1245\n0.017\n-7.265\n0.000\n-0.158\n-0.091\n\n\nroom_type_Shared room\n-0.2346\n0.049\n-4.813\n0.000\n-0.330\n-0.139\n\n\ninstant_bookable_t\n0.4977\n0.021\n23.979\n0.000\n0.457\n0.538\n\n\ndays\n0.4489\n0.009\n51.265\n0.000\n0.432\n0.466\n\n\nbathrooms\n-0.0289\n0.009\n-3.372\n0.001\n-0.046\n-0.012\n\n\nbedrooms\n0.0653\n0.009\n7.203\n0.000\n0.048\n0.083\n\n\nprice\n-0.0560\n0.006\n-8.843\n0.000\n-0.068\n-0.044\n\n\nalpha\n2.6011\n0.019\n139.327\n0.000\n2.565\n2.638\n\n\n\n\n\nThe Negative Binomial regression model with scaled data has successfully converged, and here are the results:\n\nModel Coefficients Interpretation:\n\nConstant (Intercept): The base log-count of reviews when all predictors are at their mean values is approximately 2.6279.\nDays (0.4489): The scaled coefficient suggests a strong positive impact of the number of days listed on the number of reviews, indicating that older listings tend to have more reviews.\nBathrooms (-0.0289): More bathrooms in a listing slightly decrease the expected count of reviews, potentially due to higher costs or specific types of properties.\nBedrooms (0.0653): More bedrooms slightly increase the number of reviews, consistent with the capacity to host more guests.\nPrice (-0.0560): Higher prices reduce the expected count of reviews, implying that more expensive listings may be booked less frequently.\nRoom Type (Private and Shared): Both private and shared rooms receive fewer reviews compared to entire homes/apartments, with shared rooms experiencing a larger decrease.\nInstant Bookable (0.4977): Listings that are instantly bookable have significantly more reviews, reinforcing the value of convenience.\nAlpha (2.6011): The dispersion parameter remains high, indicating appropriate use of the Negative Binomial model due to overdispersion in the data.\n\n\n\n\nDiagnostic Checks:\nFurther diagnostic checks should be performed to ensure the model fits well and the assumptions hold.\n\n# Model Diagnostics for the Negative Binomial Regression Model\nfrom statsmodels.graphics.gofplots import qqplot\n\n# Plotting the residuals\nresiduals = nb_model_scaled.resid_response\n\n# Creating diagnostic plots\nfig, ax = plt.subplots(1, 2, figsize=(6, 8))\n\n# Q-Q plot for residuals to check normality\nqqplot(residuals, line='45', ax=ax[0])\nax[0].set_title('Q-Q Plot of Residuals')\n\n# Residuals plot to check homoscedasticity and outliers\nsns.histplot(residuals, bins=50, kde=True, ax=ax[1])\nax[1].set_title('Histogram of Residuals')\n\nplt.show()\n\n# Checking for patterns in residuals\nplt.figure(figsize=(8, 6))\nplt.scatter(y_scaled, residuals)\nplt.title('Residuals vs Fitted Values')\nplt.xlabel('Fitted Values')\nplt.ylabel('Residuals')\nplt.axhline(y=0, color='red', linestyle='--')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiagnostic Checks Analysis:\nHere’s an overview of the diagnostic checks for the Negative Binomial regression model:\n\nQ-Q Plot of Residuals:\n\n\nThis plot helps assess the normality of residuals. Ideally, the residuals should lie along the 45-degree line if they are normally distributed. Deviations from this line suggest departures from normality, which could indicate issues with model fit or assumptions.\n\n\nHistogram of Residuals:\n\n\nThe histogram provides a visual representation of the distribution of residuals. It appears the residuals are not perfectly normally distributed, showing some skewness. This is not unusual for count data models, but it does suggest checking whether the model assumptions are adequately met.\n\n\nResiduals vs. Fitted Values:\n\n\nIdeally, there should be no clear pattern or systematic structure in this plot. The presence of patterns or trends could indicate issues with model fit, such as non-linearity or omitted variables. The plot here does not show a clear pattern, which generally suggests that the model does not suffer from obvious issues like heteroscedasticity or non-linear relationships that have not been accounted for.\n\nConclusion:\nThe diagnostics suggest that while the residuals do not follow a perfect normal distribution (which is common in count data models), there aren’t clear signs of heteroscedasticity or problematic patterns between the residuals and fitted values. However, the slight deviation in the Q-Q plot and the distribution of residuals could indicate that further model adjustments or transformations might be beneficial, especially to better handle any underlying skewness or overdispersion not fully accounted for."
  },
  {
    "objectID": "projects/project1/hw2_questions.html#step-5-compared-with-two-different-model",
    "href": "projects/project1/hw2_questions.html#step-5-compared-with-two-different-model",
    "title": "Homework2 - Poisson Regression Examples",
    "section": "Step 5: Compared with two different model",
    "text": "Step 5: Compared with two different model\n\n# Extracting summaries and key metrics from both models\npoisson_summary = poisson_model.summary2().tables[1]\nnb_summary = nb_model_scaled.summary2().tables[1]\n\n# Extracting AIC values for comparison\npoisson_aic = poisson_model.aic\nnb_aic = nb_model_scaled.aic\n\n# Print extracted information for comparison\npoisson_summary, nb_summary, poisson_aic, nb_aic\n\n(                           Coef.  Std.Err.           z          P&gt;|z|  \\\n const                   2.011204  0.005161  389.655130   0.000000e+00   \n days                    0.000635  0.000002  347.039693   0.000000e+00   \n bathrooms              -0.101692  0.003860  -26.347951  5.417525e-153   \n bedrooms                0.096588  0.002051   47.084526   0.000000e+00   \n price                  -0.000471  0.000012  -38.120430   0.000000e+00   \n room_type_Private room -0.093477  0.002841  -32.900956  2.129728e-237   \n room_type_Shared room  -0.224037  0.008653  -25.890075  8.614729e-148   \n instant_bookable_t      0.515349  0.002897  177.862919   0.000000e+00   \n \n                           [0.025    0.975]  \n const                   2.001088  2.021321  \n days                    0.000631  0.000638  \n bathrooms              -0.109257 -0.094128  \n bedrooms                0.092567  0.100608  \n price                  -0.000496 -0.000447  \n room_type_Private room -0.099045 -0.087908  \n room_type_Shared room  -0.240997 -0.207076  \n instant_bookable_t      0.509671  0.521028  ,\n                            Coef.  Std.Err.           z          P&gt;|z|  \\\n const                   2.627909  0.012327  213.189580   0.000000e+00   \n room_type_Private room -0.124480  0.017134   -7.264982   3.730870e-13   \n room_type_Shared room  -0.234617  0.048745   -4.813152   1.485681e-06   \n instant_bookable_t      0.497733  0.020757   23.978780  4.630527e-127   \n days                    0.448946  0.008757   51.265297   0.000000e+00   \n bathrooms              -0.028936  0.008582   -3.371777   7.468502e-04   \n bedrooms                0.065332  0.009069    7.203462   5.870261e-13   \n price                  -0.055952  0.006327   -8.843272   9.295565e-19   \n alpha                   2.601094  0.018669  139.327051   0.000000e+00   \n \n                           [0.025    0.975]  \n const                   2.603750  2.652069  \n room_type_Private room -0.158063 -0.090898  \n room_type_Shared room  -0.330155 -0.139079  \n instant_bookable_t      0.457050  0.538417  \n days                    0.431782  0.466110  \n bathrooms              -0.045756 -0.012116  \n bedrooms                0.047556  0.083108  \n price                  -0.068352 -0.043551  \n alpha                   2.564503  2.637684  ,\n 1324704.7950103276,\n 279072.9591164948)\n\n\n\npoisson_aic, nb_aic\n\n(1324704.7950103276, 279072.9591164948)\n\n\nModel Coefficients Both models show similar directions in the influence of predictors:\nDays, bedrooms, and instant bookable status positively affect the number of reviews. Price and higher bathrooms negatively affect reviews, more so in the Poisson model.\nRoom type variations show that private and shared rooms generally receive fewer reviews compared to entire homes/apartments.\nGoodness-of-Fit Indicators\nPoisson Model: Generally showed signs of underfitting due to overdispersion, indicated by high deviance.\nNegative Binomial Model: Improved fit, accommodating overdispersion with the inclusion of the dispersion parameter (alpha).\nPredictive Performance A formal comparison using cross-validation or split-sample testing would be ideal to assess this aspect, but from the fitting process:\nNegative Binomial Model: Likely provides more reliable predictions due to better handling of data variability.\nAIC Values\nThe Negative Binomial model show a lower AIC when fitting count data with overdispersion, indicating a better balance of model fit and complexity.\nConclusion:\nPoisson regression model\nThe Poisson regression model reveals several important factors influencing the number of reviews an Airbnb listing receives. The duration a listing has been posted and whether it is instantly bookable significantly increase reviews, reflecting longer exposure and user convenience. In contrast, higher prices and more bathrooms decrease the number of reviews, which may be related to the target market and affordability.\nNegative Binomial model\nThe Negative Binomial model provides a robust framework for understanding factors that influence the number of reviews an Airbnb listing receives. It accounts for overdispersion in the data, making it a more reliable choice than the Poisson model for this dataset. The results indicate that practical features such as duration of listing, type of room, and instant bookability significantly affect guest interaction in terms of reviews. Listings that are more affordable, offer convenience, and cater to larger groups tend to receive more reviews.\nImplications:\nPoisson regression model\nThese findings can inform Airbnb hosts about optimizing their listings for more reviews and potentially more bookings. For instance, setting competitive prices and offering instant booking options could enhance a listing’s attractiveness and activity. Hosts with properties having multiple bathrooms may need to consider their pricing strategy or marketing approach, particularly if targeting larger groups or longer stays.\nNegative Binomial model\nThis model can guide Airbnb hosts in optimizing their properties to attract more reviews, which can enhance visibility and booking probabilities on the platform. For instance, setting competitive prices, improving the quality of shared rooms, and ensuring listings are instantly bookable could boost guest engagement and satisfaction."
  },
  {
    "objectID": "projects/project1/hw2_questions.html#step-5-compared-with-two-different-models",
    "href": "projects/project1/hw2_questions.html#step-5-compared-with-two-different-models",
    "title": "Homework2 - Poisson Regression Examples",
    "section": "Step 5: Compared with two different models",
    "text": "Step 5: Compared with two different models\n\n# Extracting AIC values for comparison\npoisson_aic = poisson_model.aic\nnb_aic = nb_model_scaled.aic\n\nprint('AIC of Poisson Model is',poisson_aic) \nprint('AIC of Negative Binomial Model is',nb_aic)\n\nAIC of Poisson Model is 1324704.7950103276\nAIC of Negative Binomial Model is 279072.9591164948\n\n\n\nModel Coefficients:\nBoth models show similar directions in the influence of predictors:\nDays, bedrooms, and instant bookable status positively affect the number of reviews. Price and higher bathrooms negatively affect reviews, more so in the Poisson model.\nRoom type variations show that private and shared rooms generally receive fewer reviews compared to entire homes/apartments.\n\n\nGoodness-of-Fit Indicators:\nPoisson Model: Generally showed signs of underfitting due to overdispersion, indicated by high deviance.\nNegative Binomial Model: Improved fit, accommodating overdispersion with the inclusion of the dispersion parameter (alpha).\n\n\nPredictive Performance:\nA formal comparison using cross-validation or split-sample testing would be ideal to assess this aspect, but from the fitting process:\nNegative Binomial Model: Likely provides more reliable predictions due to better handling of data variability.\n\n\nAIC Values:\nThe Negative Binomial model show a lower AIC when fitting count data with overdispersion, indicating a better balance of model fit and complexity.\n\n\nConclusion:\nPoisson regression model:\nThe Poisson regression model reveals several important factors influencing the number of reviews an Airbnb listing receives. The duration a listing has been posted and whether it is instantly bookable significantly increase reviews, reflecting longer exposure and user convenience. In contrast, higher prices and more bathrooms decrease the number of reviews, which may be related to the target market and affordability.\nNegative Binomial model:\nThe Negative Binomial model provides a robust framework for understanding factors that influence the number of reviews an Airbnb listing receives. It accounts for overdispersion in the data, making it a more reliable choice than the Poisson model for this dataset. The results indicate that practical features such as duration of listing, type of room, and instant bookability significantly affect guest interaction in terms of reviews. Listings that are more affordable, offer convenience, and cater to larger groups tend to receive more reviews.\n\n\nImplications:\nPoisson regression model\nThese findings can inform Airbnb hosts about optimizing their listings for more reviews and potentially more bookings. For instance, setting competitive prices and offering instant booking options could enhance a listing’s attractiveness and activity. Hosts with properties having multiple bathrooms may need to consider their pricing strategy or marketing approach, particularly if targeting larger groups or longer stays.\nNegative Binomial model\nThis model can guide Airbnb hosts in optimizing their properties to attract more reviews, which can enhance visibility and booking probabilities on the platform. Showing similar implications with the Poisson regression model."
  }
]